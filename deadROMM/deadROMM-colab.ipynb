{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"deadROMM-colab.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"ZeXXd1p9X9jw","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","!pip install certifi chardet click easydict h5py~=2.7 intel-openmp imgaug ipython ipython-genutils matplotlib==3.0.3 moviepy numpy==1.16.4 opencv-python~=3.4 pandas patsy \n","!pip install python-dateutil pyyaml>=5.1 requests ruamel.yaml~=0.15 setuptools scikit-image scikit-learn scipy six statsmodels tables tensorpack>=0.9.7.1 tqdm wheel\n","%tensorflow_version 1.x\n","import sys\n","import os\n","import importlib\n","os.environ[\"DLClight\"]=\"True\"\n","%cd drive/My\\ Drive/Development/DeepLabCut\n","import deeplabcut\n","from deadROMM import possumPolish"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tz2IjevXktzJ","colab_type":"code","colab":{}},"source":["importlib.reload(possumPolish)\n","model = possumPolish.Project()\n","# model.load('./deadROMM/profiles-colab.yaml','sm108')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nmi3t6s5SpKS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"60a56b02-4912-4348-c3d4-c4c81660fbe1","executionInfo":{"status":"ok","timestamp":1591709843577,"user_tz":240,"elapsed":369,"user":{"displayName":"Phil Fahn-Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgaLRzhwWuE2_ZNOkUUkb6lkk-noGiIsb7ucOzW=s64","userId":"13631433551768862211"}}},"source":["model.getOutliers.__doc__"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Independently identifies outlier frames for two cameras, extracts the corresponding frames, and converts DeepLabCut predictions for those frames to XMALab format\\n        Parameters:\\n        num2extract (int): Number of outlier frames to pick from each camera. Used to overwrite the numframes2pick paramter in config.yaml\\n        make_labels (bool): If true, tells DeepLabCut to create duplicate pngs with marker predictions visualized\\n        Returns:\\n        None\\n        '"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"8MfeZezdk-6d","colab_type":"code","outputId":"1ab48fc9-14e2-4c5b-e04b-49d63bd3bfa9","executionInfo":{"status":"ok","timestamp":1590453054118,"user_tz":240,"elapsed":313,"user":{"displayName":"Phil Fahn-Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgaLRzhwWuE2_ZNOkUUkb6lkk-noGiIsb7ucOzW=s64","userId":"13631433551768862211"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["model.load('dv101',config_path) # 1. create a new dlc project with raw videos, extract 20 frames with k-means from each video, grab 40 frames total from each of two vids, stores frame paths and indices in frame_log.yaml\n","\n","trainposeconfigfile,testposeconfigfile,snapshotfolder=model.dlc.return_train_network_path(config_path,1,0.95)\n","cfg_dlc=model.dlc.auxiliaryfunctions.read_plainconfig(trainposeconfigfile)\n","cfg_dlc['augmentationprobability']=0.5\n","cfg_dlc['batch_size']=3\n","cfg_dlc['hist_eq']=True\n","cfg_dlc['gamma']=True\n","cfg_dlc['logcontrast']=True\n","cfg_dlc['allchannelsclahe']=True\n","cfg_dlc['optimizer'] =\"adam\"\n","cfg_dlc['dataset_type']='imgaug'\n","# cfg_dlc['multi_step']=[[1e-4, 7500], [5*1e-5, 12000], [1e-5, 50000], [5e-6, 200000]]\n","\n","model.dlc.auxiliaryfunctions.write_plainconfig(trainposeconfigfile,cfg_dlc)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Development/DeadROMM/possumPolish.py:115: UnsafeLoaderWarning: \n","The default 'Loader' for 'load(stream)' without further arguments can be unsafe.\n","Use 'load(stream, Loader=ruamel.yaml.Loader)' explicitly if that is OK.\n","Alternatively include the following in your code:\n","\n","  import warnings\n","  warnings.simplefilter('ignore', ruamel.yaml.error.UnsafeLoaderWarning)\n","\n","In most other cases you should consider using 'safe_load(stream)'\n","  profiles = ruamel.yaml.load(open(self.profile_path))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"_Ua1pjwQuCZj","colab_type":"code","outputId":"099589e1-96dd-4f19-96d1-5158d2c6649c","executionInfo":{"status":"error","timestamp":1590503211441,"user_tz":240,"elapsed":8796674,"user":{"displayName":"Phil Fahn-Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgaLRzhwWuE2_ZNOkUUkb6lkk-noGiIsb7ucOzW=s64","userId":"13631433551768862211"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.dlc.train_network(config_path, saveiters=10000,displayiters=50,maxiters=300000,max_snapshots_to_keep=15, allow_growth=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Config:\n","{'all_joints': [[0],\n","                [1],\n","                [2],\n","                [3],\n","                [4],\n","                [5],\n","                [6],\n","                [7],\n","                [8],\n","                [9],\n","                [10],\n","                [11],\n","                [12],\n","                [13],\n","                [14],\n","                [15],\n","                [16],\n","                [17],\n","                [18],\n","                [19],\n","                [20],\n","                [21],\n","                [22],\n","                [23],\n","                [24],\n","                [25],\n","                [26],\n","                [27],\n","                [28],\n","                [29],\n","                [30],\n","                [31],\n","                [32],\n","                [33],\n","                [34],\n","                [35],\n","                [36],\n","                [37],\n","                [38],\n","                [39],\n","                [40],\n","                [41],\n","                [42],\n","                [43]],\n"," 'all_joints_names': ['Body_ds1_crn_cam1',\n","                      'Body_ds1_crn_cam2',\n","                      'Body_ds2_int_cam1',\n","                      'Body_ds2_int_cam2',\n","                      'Body_ds3_cdl_cam1',\n","                      'Body_ds3_cdl_cam2',\n","                      'Body_vn1_crn_cam1',\n","                      'Body_vn1_crn_cam2',\n","                      'Body_vn2_int_cam1',\n","                      'Body_vn2_int_cam2',\n","                      'Body_vn3_cdl_cam1',\n","                      'Body_vn3_cdl_cam2',\n","                      'Scapula_acr_cam1',\n","                      'Scapula_acr_cam2',\n","                      'Scapula_spi_cam1',\n","                      'Scapula_spi_cam2',\n","                      'Scapula_vtb_cam1',\n","                      'Scapula_vtb_cam2',\n","                      'Humerus_dpc_cam1',\n","                      'Humerus_dpc_cam2',\n","                      'Humerus_ent_cam1',\n","                      'Humerus_ent_cam2',\n","                      'Humerus_ect_cam1',\n","                      'Humerus_ect_cam2',\n","                      'Ulna_olc_cam1',\n","                      'Ulna_olc_cam2',\n","                      'Ulna_int_cam1',\n","                      'Ulna_int_cam2',\n","                      'Ulna_dst_cam1',\n","                      'Ulna_dst_cam2',\n","                      'Radius_prx_cam1',\n","                      'Radius_prx_cam2',\n","                      'Radius_int_cam1',\n","                      'Radius_int_cam2',\n","                      'Radius_dst_cam1',\n","                      'Radius_dst_cam2',\n","                      'Teres_maj_prx_cam1',\n","                      'Teres_maj_prx_cam2',\n","                      'Teres_maj_dst_cam1',\n","                      'Teres_maj_dst_cam2',\n","                      'Biceps_prx_cam1',\n","                      'Biceps_prx_cam2',\n","                      'Biceps_dst_cam1',\n","                      'Biceps_dst_cam2'],\n"," 'allchannelsclahe': True,\n"," 'augmentationprobability': 0.5,\n"," 'batch_size': 3,\n"," 'bottomheight': 400,\n"," 'covering': True,\n"," 'crop': True,\n"," 'crop_pad': 0,\n"," 'cropratio': 0.4,\n"," 'dataset': 'training-datasets/iteration-3/UnaugmentedDataSet_possum101_11AprApr13/possum101_11Apr_Phil95shuffle1.mat',\n"," 'dataset_type': 'imgaug',\n"," 'deterministic': False,\n"," 'display_iters': 1000,\n"," 'fg_fraction': 0.25,\n"," 'gamma': True,\n"," 'global_scale': 0.8,\n"," 'hist_eq': True,\n"," 'init_weights': '/content/drive/My '\n","                 'Drive/Development/DeadROMM/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n"," 'intermediate_supervision': False,\n"," 'intermediate_supervision_layer': 12,\n"," 'leftwidth': 400,\n"," 'location_refinement': True,\n"," 'locref_huber_loss': True,\n"," 'locref_loss_weight': 0.05,\n"," 'locref_stdev': 7.2801,\n"," 'log_dir': 'log',\n"," 'logcontrast': True,\n"," 'max_input_size': 1500,\n"," 'mean_pixel': [123.68, 116.779, 103.939],\n"," 'metadataset': 'training-datasets/iteration-3/UnaugmentedDataSet_possum101_11AprApr13/Documentation_data-possum101_11Apr_95shuffle1.pickle',\n"," 'min_input_size': 64,\n"," 'minsize': 100,\n"," 'mirror': False,\n"," 'multi_step': [[0.005, 10000],\n","                [0.02, 430000],\n","                [0.002, 730000],\n","                [0.001, 1030000]],\n"," 'net_type': 'resnet_50',\n"," 'num_joints': 44,\n"," 'optimizer': 'adam',\n"," 'pos_dist_thresh': 17,\n"," 'project_path': '/content/drive/My '\n","                 'Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff',\n"," 'regularize': False,\n"," 'rightwidth': 400,\n"," 'save_iters': 50000,\n"," 'scale_jitter_lo': 0.5,\n"," 'scale_jitter_up': 1.5,\n"," 'scoremap_dir': 'test',\n"," 'shuffle': True,\n"," 'snapshot_prefix': '/content/drive/My '\n","                    'Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/dlc-models/iteration-3/possum101_11AprApr13-trainset95shuffle1/train/snapshot',\n"," 'stride': 8.0,\n"," 'topheight': 400,\n"," 'weigh_negatives': False,\n"," 'weigh_only_present_joints': False,\n"," 'weigh_part_predictions': False,\n"," 'weight_decay': 0.0001}\n"],"name":"stderr"},{"output_type":"stream","text":["Starting with imgaug pose-dataset loader.\n","Batch Size is 3\n","Initializing ResNet\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/drive/My Drive/Development/DeadROMM/deeplabcut/pose_estimation_tensorflow/nnet/pose_net.py:62: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Development/DeadROMM/deeplabcut/pose_estimation_tensorflow/nnet/pose_net.py:160: The name tf.losses.sigmoid_cross_entropy is deprecated. Please use tf.compat.v1.losses.sigmoid_cross_entropy instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/drive/My Drive/Development/DeadROMM/deeplabcut/pose_estimation_tensorflow/nnet/losses.py:38: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","Loading ImageNet-pretrained resnet_50\n","WARNING:tensorflow:From /content/drive/My Drive/Development/DeadROMM/deeplabcut/pose_estimation_tensorflow/train.py:143: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Development/DeadROMM/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt\n","Max_iters overwritten as 300000\n","Display_iters overwritten as 50\n","Save_iters overwritten as 10000\n","Training parameter:\n","{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'weigh_only_present_joints': False, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': '/content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/dlc-models/iteration-3/possum101_11AprApr13-trainset95shuffle1/train/snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'adam', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 3, 'dataset_type': 'imgaug', 'deterministic': False, 'crop': True, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43]], 'all_joints_names': ['Body_ds1_crn_cam1', 'Body_ds1_crn_cam2', 'Body_ds2_int_cam1', 'Body_ds2_int_cam2', 'Body_ds3_cdl_cam1', 'Body_ds3_cdl_cam2', 'Body_vn1_crn_cam1', 'Body_vn1_crn_cam2', 'Body_vn2_int_cam1', 'Body_vn2_int_cam2', 'Body_vn3_cdl_cam1', 'Body_vn3_cdl_cam2', 'Scapula_acr_cam1', 'Scapula_acr_cam2', 'Scapula_spi_cam1', 'Scapula_spi_cam2', 'Scapula_vtb_cam1', 'Scapula_vtb_cam2', 'Humerus_dpc_cam1', 'Humerus_dpc_cam2', 'Humerus_ent_cam1', 'Humerus_ent_cam2', 'Humerus_ect_cam1', 'Humerus_ect_cam2', 'Ulna_olc_cam1', 'Ulna_olc_cam2', 'Ulna_int_cam1', 'Ulna_int_cam2', 'Ulna_dst_cam1', 'Ulna_dst_cam2', 'Radius_prx_cam1', 'Radius_prx_cam2', 'Radius_int_cam1', 'Radius_int_cam2', 'Radius_dst_cam1', 'Radius_dst_cam2', 'Teres_maj_prx_cam1', 'Teres_maj_prx_cam2', 'Teres_maj_dst_cam1', 'Teres_maj_dst_cam2', 'Biceps_prx_cam1', 'Biceps_prx_cam2', 'Biceps_dst_cam1', 'Biceps_dst_cam2'], 'allchannelsclahe': True, 'augmentationprobability': 0.5, 'covering': True, 'dataset': 'training-datasets/iteration-3/UnaugmentedDataSet_possum101_11AprApr13/possum101_11Apr_Phil95shuffle1.mat', 'display_iters': 1000, 'gamma': True, 'hist_eq': True, 'init_weights': '/content/drive/My Drive/Development/DeadROMM/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt', 'logcontrast': True, 'max_input_size': 1500, 'metadataset': 'training-datasets/iteration-3/UnaugmentedDataSet_possum101_11AprApr13/Documentation_data-possum101_11Apr_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 44, 'pos_dist_thresh': 17, 'project_path': '/content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff', 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.5, 'output_stride': 16, 'deconvolutionstride': 2}\n","Starting training....\n"],"name":"stdout"},{"output_type":"stream","text":["iteration: 50 loss: 2082749371204.9773 lr: 0.005\n","iteration: 100 loss: 912533.3978 lr: 0.005\n","iteration: 150 loss: 254185943.7935 lr: 0.005\n","iteration: 200 loss: 18082774062705.8086 lr: 0.005\n","iteration: 250 loss: 291847611051842.8125 lr: 0.005\n","iteration: 300 loss: 16027050000.8000 lr: 0.005\n","iteration: 350 loss: 1616491712720.1599 lr: 0.005\n","iteration: 400 loss: 2238826277061941.0000 lr: 0.005\n","iteration: 450 loss: 746032491876602.8750 lr: 0.005\n","iteration: 500 loss: 3634789509736694.0000 lr: 0.005\n","iteration: 550 loss: 44740014894202.8828 lr: 0.005\n","iteration: 600 loss: 708718737413997824.0000 lr: 0.005\n","iteration: 650 loss: 0.0418 lr: 0.005\n","iteration: 700 loss: 0.0342 lr: 0.005\n","iteration: 750 loss: 0.0349 lr: 0.005\n","iteration: 800 loss: 0.0319 lr: 0.005\n","iteration: 850 loss: 0.0339 lr: 0.005\n","iteration: 900 loss: 0.0334 lr: 0.005\n","iteration: 950 loss: 0.0323 lr: 0.005\n","iteration: 1000 loss: 0.0315 lr: 0.005\n","iteration: 1050 loss: 0.0315 lr: 0.005\n","iteration: 1100 loss: 0.0332 lr: 0.005\n","iteration: 1150 loss: 0.0291 lr: 0.005\n","iteration: 1200 loss: 0.0325 lr: 0.005\n","iteration: 1250 loss: 0.0340 lr: 0.005\n","iteration: 1300 loss: 0.0316 lr: 0.005\n","iteration: 1350 loss: 0.0313 lr: 0.005\n","iteration: 1400 loss: 0.0323 lr: 0.005\n","iteration: 1450 loss: 0.0322 lr: 0.005\n","iteration: 1500 loss: 0.0339 lr: 0.005\n","iteration: 1550 loss: 0.0333 lr: 0.005\n","iteration: 1600 loss: 0.0339 lr: 0.005\n","iteration: 1650 loss: 0.0326 lr: 0.005\n","iteration: 1700 loss: 0.0331 lr: 0.005\n","iteration: 1750 loss: 0.0328 lr: 0.005\n","iteration: 1800 loss: 0.0319 lr: 0.005\n","iteration: 1850 loss: 0.0309 lr: 0.005\n","iteration: 1900 loss: 0.0286 lr: 0.005\n","iteration: 1950 loss: 0.0318 lr: 0.005\n","iteration: 2000 loss: 0.0349 lr: 0.005\n","iteration: 2050 loss: 0.0330 lr: 0.005\n","iteration: 2100 loss: 0.0322 lr: 0.005\n","iteration: 2150 loss: 0.0300 lr: 0.005\n","iteration: 2200 loss: 0.0319 lr: 0.005\n","iteration: 2250 loss: 0.0315 lr: 0.005\n","iteration: 2300 loss: 0.0280 lr: 0.005\n","iteration: 2350 loss: 0.0348 lr: 0.005\n","iteration: 2400 loss: 0.0288 lr: 0.005\n","iteration: 2450 loss: 0.0348 lr: 0.005\n","iteration: 2500 loss: 0.0332 lr: 0.005\n","iteration: 2550 loss: 0.0327 lr: 0.005\n","iteration: 2600 loss: 0.0286 lr: 0.005\n","iteration: 2650 loss: 0.0347 lr: 0.005\n","iteration: 2700 loss: 0.0346 lr: 0.005\n","iteration: 2750 loss: 0.0292 lr: 0.005\n","iteration: 2800 loss: 0.0283 lr: 0.005\n","iteration: 2850 loss: 0.0304 lr: 0.005\n","iteration: 2900 loss: 0.0306 lr: 0.005\n","iteration: 2950 loss: 0.0309 lr: 0.005\n","iteration: 3000 loss: 0.0323 lr: 0.005\n","iteration: 3050 loss: 0.0315 lr: 0.005\n","iteration: 3100 loss: 0.0314 lr: 0.005\n","iteration: 3150 loss: 0.0338 lr: 0.005\n","iteration: 3200 loss: 0.0343 lr: 0.005\n","iteration: 3250 loss: 0.0318 lr: 0.005\n","iteration: 3300 loss: 0.0309 lr: 0.005\n","iteration: 3350 loss: 0.0329 lr: 0.005\n","iteration: 3400 loss: 0.0315 lr: 0.005\n","iteration: 3450 loss: 0.0315 lr: 0.005\n","iteration: 3500 loss: 0.0308 lr: 0.005\n","iteration: 3550 loss: 0.0347 lr: 0.005\n","iteration: 3600 loss: 0.0332 lr: 0.005\n","iteration: 3650 loss: 0.0322 lr: 0.005\n","iteration: 3700 loss: 0.0306 lr: 0.005\n","iteration: 3750 loss: 0.0341 lr: 0.005\n","iteration: 3800 loss: 0.0293 lr: 0.005\n","iteration: 3850 loss: 0.0301 lr: 0.005\n","iteration: 3900 loss: 0.0336 lr: 0.005\n","iteration: 3950 loss: 0.0323 lr: 0.005\n","iteration: 4000 loss: 0.0273 lr: 0.005\n","iteration: 4050 loss: 0.0323 lr: 0.005\n","iteration: 4100 loss: 0.0288 lr: 0.005\n","iteration: 4150 loss: 0.0325 lr: 0.005\n","iteration: 4200 loss: 0.0342 lr: 0.005\n","iteration: 4250 loss: 0.0334 lr: 0.005\n","iteration: 4300 loss: 0.0325 lr: 0.005\n","iteration: 4350 loss: 0.0324 lr: 0.005\n","iteration: 4400 loss: 0.0325 lr: 0.005\n","iteration: 4450 loss: 0.0325 lr: 0.005\n","iteration: 4500 loss: 0.0319 lr: 0.005\n","iteration: 4550 loss: 0.0297 lr: 0.005\n","iteration: 4600 loss: 0.0291 lr: 0.005\n","iteration: 4650 loss: 0.0296 lr: 0.005\n","iteration: 4700 loss: 0.0302 lr: 0.005\n","iteration: 4750 loss: 0.0304 lr: 0.005\n","iteration: 4800 loss: 0.0305 lr: 0.005\n","iteration: 4850 loss: 0.0341 lr: 0.005\n","iteration: 4900 loss: 0.0296 lr: 0.005\n","iteration: 4950 loss: 0.0341 lr: 0.005\n","iteration: 5000 loss: 0.0284 lr: 0.005\n","iteration: 5050 loss: 0.0315 lr: 0.005\n","iteration: 5100 loss: 0.0299 lr: 0.005\n","iteration: 5150 loss: 0.0274 lr: 0.005\n","iteration: 5200 loss: 0.0310 lr: 0.005\n","iteration: 5250 loss: 0.0291 lr: 0.005\n","iteration: 5300 loss: 0.0336 lr: 0.005\n","iteration: 5350 loss: 0.0327 lr: 0.005\n","iteration: 5400 loss: 0.0329 lr: 0.005\n","iteration: 5450 loss: 0.0349 lr: 0.005\n","iteration: 5500 loss: 0.0318 lr: 0.005\n","iteration: 5550 loss: 0.0311 lr: 0.005\n","iteration: 5600 loss: 0.0301 lr: 0.005\n","iteration: 5650 loss: 0.0302 lr: 0.005\n","iteration: 5700 loss: 0.0327 lr: 0.005\n","iteration: 5750 loss: 0.0328 lr: 0.005\n","iteration: 5800 loss: 0.0332 lr: 0.005\n","iteration: 5850 loss: 0.0319 lr: 0.005\n","iteration: 5900 loss: 0.0308 lr: 0.005\n","iteration: 5950 loss: 0.0303 lr: 0.005\n","iteration: 6000 loss: 0.0340 lr: 0.005\n","iteration: 6050 loss: 0.0301 lr: 0.005\n","iteration: 6100 loss: 0.0303 lr: 0.005\n","iteration: 6150 loss: 0.0343 lr: 0.005\n","iteration: 6200 loss: 0.0282 lr: 0.005\n","iteration: 6250 loss: 0.0288 lr: 0.005\n","iteration: 6300 loss: 0.0349 lr: 0.005\n","iteration: 6350 loss: 0.0258 lr: 0.005\n","iteration: 6400 loss: 0.0325 lr: 0.005\n","iteration: 6450 loss: 0.0369 lr: 0.005\n","iteration: 6500 loss: 0.0292 lr: 0.005\n","iteration: 6550 loss: 0.0324 lr: 0.005\n","iteration: 6600 loss: 0.0296 lr: 0.005\n","iteration: 6650 loss: 0.0342 lr: 0.005\n","iteration: 6700 loss: 0.0316 lr: 0.005\n","iteration: 6750 loss: 0.0313 lr: 0.005\n","iteration: 6800 loss: 0.0329 lr: 0.005\n","iteration: 6850 loss: 0.0280 lr: 0.005\n","iteration: 6900 loss: 0.0331 lr: 0.005\n","iteration: 6950 loss: 0.0302 lr: 0.005\n","iteration: 7000 loss: 0.0320 lr: 0.005\n","iteration: 7050 loss: 0.0334 lr: 0.005\n","iteration: 7100 loss: 0.0329 lr: 0.005\n","iteration: 7150 loss: 0.0311 lr: 0.005\n","iteration: 7200 loss: 0.0338 lr: 0.005\n","iteration: 7250 loss: 0.0273 lr: 0.005\n","iteration: 7300 loss: 0.0316 lr: 0.005\n","iteration: 7350 loss: 0.0294 lr: 0.005\n","iteration: 7400 loss: 0.0291 lr: 0.005\n","iteration: 7450 loss: 0.0310 lr: 0.005\n","iteration: 7500 loss: 0.0337 lr: 0.005\n","iteration: 7550 loss: 0.0274 lr: 0.005\n","iteration: 7600 loss: 0.0298 lr: 0.005\n","iteration: 7650 loss: 0.0286 lr: 0.005\n","iteration: 7700 loss: 0.0313 lr: 0.005\n","iteration: 7750 loss: 0.0299 lr: 0.005\n","iteration: 7800 loss: 0.0330 lr: 0.005\n","iteration: 7850 loss: 0.0306 lr: 0.005\n","iteration: 7900 loss: 0.0293 lr: 0.005\n","iteration: 7950 loss: 0.0321 lr: 0.005\n","iteration: 8000 loss: 0.0301 lr: 0.005\n","iteration: 8050 loss: 0.0333 lr: 0.005\n","iteration: 8100 loss: 0.0366 lr: 0.005\n","iteration: 8150 loss: 0.0305 lr: 0.005\n","iteration: 8200 loss: 0.0283 lr: 0.005\n","iteration: 8250 loss: 0.0294 lr: 0.005\n","iteration: 8300 loss: 0.0316 lr: 0.005\n","iteration: 8350 loss: 0.0266 lr: 0.005\n","iteration: 8400 loss: 0.0322 lr: 0.005\n","iteration: 8450 loss: 0.0333 lr: 0.005\n","iteration: 8500 loss: 0.0300 lr: 0.005\n","iteration: 8550 loss: 0.0340 lr: 0.005\n","iteration: 8600 loss: 0.0310 lr: 0.005\n","iteration: 8650 loss: 0.0315 lr: 0.005\n","iteration: 8700 loss: 0.0299 lr: 0.005\n","iteration: 8750 loss: 0.0298 lr: 0.005\n","iteration: 8800 loss: 0.0311 lr: 0.005\n","iteration: 8850 loss: 0.0322 lr: 0.005\n","iteration: 8900 loss: 0.0326 lr: 0.005\n","iteration: 8950 loss: 0.0321 lr: 0.005\n","iteration: 9000 loss: 0.0295 lr: 0.005\n","iteration: 9050 loss: 0.0313 lr: 0.005\n","iteration: 9100 loss: 0.0304 lr: 0.005\n","iteration: 9150 loss: 0.0308 lr: 0.005\n","iteration: 9200 loss: 0.0319 lr: 0.005\n","iteration: 9250 loss: 0.0310 lr: 0.005\n","iteration: 9300 loss: 0.0349 lr: 0.005\n","iteration: 9350 loss: 0.0276 lr: 0.005\n","iteration: 9400 loss: 0.0294 lr: 0.005\n","iteration: 9450 loss: 0.0269 lr: 0.005\n","iteration: 9500 loss: 0.0301 lr: 0.005\n","iteration: 9550 loss: 0.0304 lr: 0.005\n","iteration: 9600 loss: 0.0345 lr: 0.005\n","iteration: 9650 loss: 0.0304 lr: 0.005\n","iteration: 9700 loss: 0.0296 lr: 0.005\n","iteration: 9750 loss: 0.0323 lr: 0.005\n","iteration: 9800 loss: 0.0337 lr: 0.005\n","iteration: 9850 loss: 0.0279 lr: 0.005\n","iteration: 9900 loss: 0.0316 lr: 0.005\n","iteration: 9950 loss: 0.0304 lr: 0.005\n","iteration: 10000 loss: 0.0334 lr: 0.005\n","iteration: 10050 loss: 0.0340 lr: 0.02\n","iteration: 10100 loss: 0.0343 lr: 0.02\n","iteration: 10150 loss: 0.0325 lr: 0.02\n","iteration: 10200 loss: 0.0328 lr: 0.02\n","iteration: 10250 loss: 0.0331 lr: 0.02\n","iteration: 10300 loss: 0.0329 lr: 0.02\n","iteration: 10350 loss: 0.0333 lr: 0.02\n","iteration: 10400 loss: 0.0299 lr: 0.02\n","iteration: 10450 loss: 0.0339 lr: 0.02\n","iteration: 10500 loss: 0.0312 lr: 0.02\n","iteration: 10550 loss: 0.0317 lr: 0.02\n","iteration: 10600 loss: 0.0352 lr: 0.02\n","iteration: 10650 loss: 0.0304 lr: 0.02\n","iteration: 10700 loss: 0.0292 lr: 0.02\n","iteration: 10750 loss: 0.0333 lr: 0.02\n","iteration: 10800 loss: 0.0326 lr: 0.02\n","iteration: 10850 loss: 0.0311 lr: 0.02\n","iteration: 10900 loss: 0.0280 lr: 0.02\n","iteration: 10950 loss: 0.0316 lr: 0.02\n","iteration: 11000 loss: 0.0317 lr: 0.02\n","iteration: 11050 loss: 0.0286 lr: 0.02\n","iteration: 11100 loss: 0.0325 lr: 0.02\n","iteration: 11150 loss: 0.0357 lr: 0.02\n","iteration: 11200 loss: 0.0331 lr: 0.02\n","iteration: 11250 loss: 0.0329 lr: 0.02\n","iteration: 11300 loss: 0.0349 lr: 0.02\n","iteration: 11350 loss: 0.0317 lr: 0.02\n","iteration: 11400 loss: 0.0315 lr: 0.02\n","iteration: 11450 loss: 0.0328 lr: 0.02\n","iteration: 11500 loss: 0.0319 lr: 0.02\n","iteration: 11550 loss: 0.0289 lr: 0.02\n","iteration: 11600 loss: 0.0341 lr: 0.02\n","iteration: 11650 loss: 0.0337 lr: 0.02\n","iteration: 11700 loss: 0.0335 lr: 0.02\n","iteration: 11750 loss: 0.0289 lr: 0.02\n","iteration: 11800 loss: 0.0311 lr: 0.02\n","iteration: 11850 loss: 0.0338 lr: 0.02\n","iteration: 11900 loss: 0.0310 lr: 0.02\n","iteration: 11950 loss: 0.0308 lr: 0.02\n","iteration: 12000 loss: 0.0313 lr: 0.02\n","iteration: 12050 loss: 0.0320 lr: 0.02\n","iteration: 12100 loss: 0.0270 lr: 0.02\n","iteration: 12150 loss: 0.0321 lr: 0.02\n","iteration: 12200 loss: 0.0322 lr: 0.02\n","iteration: 12250 loss: 0.0316 lr: 0.02\n","iteration: 12300 loss: 0.0342 lr: 0.02\n","iteration: 12350 loss: 0.0330 lr: 0.02\n","iteration: 12400 loss: 0.0333 lr: 0.02\n","iteration: 12450 loss: 0.0357 lr: 0.02\n","iteration: 12500 loss: 0.0327 lr: 0.02\n","iteration: 12550 loss: 0.0325 lr: 0.02\n","iteration: 12600 loss: 0.0323 lr: 0.02\n","iteration: 12650 loss: 0.0309 lr: 0.02\n","iteration: 12700 loss: 0.0298 lr: 0.02\n","iteration: 12750 loss: 0.0288 lr: 0.02\n","iteration: 12800 loss: 0.0328 lr: 0.02\n","iteration: 12850 loss: 0.0319 lr: 0.02\n","iteration: 12900 loss: 0.0324 lr: 0.02\n","iteration: 12950 loss: 0.0289 lr: 0.02\n","iteration: 13000 loss: 0.0347 lr: 0.02\n","iteration: 13050 loss: 0.0304 lr: 0.02\n","iteration: 13100 loss: 0.0308 lr: 0.02\n","iteration: 13150 loss: 0.0294 lr: 0.02\n","iteration: 13200 loss: 0.0336 lr: 0.02\n","iteration: 13250 loss: 0.0278 lr: 0.02\n","iteration: 13300 loss: 0.0285 lr: 0.02\n","iteration: 13350 loss: 0.0303 lr: 0.02\n","iteration: 13400 loss: 0.0274 lr: 0.02\n","iteration: 13450 loss: 0.0344 lr: 0.02\n","iteration: 13500 loss: 0.0329 lr: 0.02\n","iteration: 13550 loss: 0.0290 lr: 0.02\n","iteration: 13600 loss: 0.0325 lr: 0.02\n","iteration: 13650 loss: 0.0309 lr: 0.02\n","iteration: 13700 loss: 0.0312 lr: 0.02\n","iteration: 13750 loss: 0.0333 lr: 0.02\n","iteration: 13800 loss: 0.0346 lr: 0.02\n","iteration: 13850 loss: 0.0305 lr: 0.02\n","iteration: 13900 loss: 0.0326 lr: 0.02\n","iteration: 13950 loss: 0.0332 lr: 0.02\n","iteration: 14000 loss: 0.0293 lr: 0.02\n","iteration: 14050 loss: 0.0317 lr: 0.02\n","iteration: 14100 loss: 0.0287 lr: 0.02\n","iteration: 14150 loss: 0.0343 lr: 0.02\n","iteration: 14200 loss: 0.0319 lr: 0.02\n","iteration: 14250 loss: 0.0301 lr: 0.02\n","iteration: 14300 loss: 0.0296 lr: 0.02\n","iteration: 14350 loss: 0.0350 lr: 0.02\n","iteration: 14400 loss: 0.0336 lr: 0.02\n","iteration: 14450 loss: 0.0303 lr: 0.02\n","iteration: 14500 loss: 0.0320 lr: 0.02\n","iteration: 14550 loss: 0.0329 lr: 0.02\n","iteration: 14600 loss: 0.0308 lr: 0.02\n","iteration: 14650 loss: 0.0283 lr: 0.02\n","iteration: 14700 loss: 0.0294 lr: 0.02\n","iteration: 14750 loss: 0.0303 lr: 0.02\n","iteration: 14800 loss: 0.0334 lr: 0.02\n","iteration: 14850 loss: 0.0313 lr: 0.02\n","iteration: 14900 loss: 0.0297 lr: 0.02\n","iteration: 14950 loss: 0.0348 lr: 0.02\n","iteration: 15000 loss: 0.0303 lr: 0.02\n","iteration: 15050 loss: 0.0323 lr: 0.02\n","iteration: 15100 loss: 0.0296 lr: 0.02\n","iteration: 15150 loss: 0.0309 lr: 0.02\n","iteration: 15200 loss: 0.0338 lr: 0.02\n","iteration: 15250 loss: 0.0295 lr: 0.02\n","iteration: 15300 loss: 0.0311 lr: 0.02\n","iteration: 15350 loss: 0.0328 lr: 0.02\n","iteration: 15400 loss: 0.0312 lr: 0.02\n","iteration: 15450 loss: 0.0314 lr: 0.02\n","iteration: 15500 loss: 0.0288 lr: 0.02\n","iteration: 15550 loss: 0.0316 lr: 0.02\n","iteration: 15600 loss: 0.0317 lr: 0.02\n","iteration: 15650 loss: 0.0353 lr: 0.02\n","iteration: 15700 loss: 0.0360 lr: 0.02\n","iteration: 15750 loss: 0.0298 lr: 0.02\n","iteration: 15800 loss: 0.0281 lr: 0.02\n","iteration: 15850 loss: 0.0325 lr: 0.02\n","iteration: 15900 loss: 0.0316 lr: 0.02\n","iteration: 15950 loss: 0.0305 lr: 0.02\n","iteration: 16000 loss: 0.0340 lr: 0.02\n","iteration: 16050 loss: 0.0314 lr: 0.02\n","iteration: 16100 loss: 0.0301 lr: 0.02\n","iteration: 16150 loss: 0.0301 lr: 0.02\n","iteration: 16200 loss: 0.0319 lr: 0.02\n","iteration: 16250 loss: 0.0339 lr: 0.02\n","iteration: 16300 loss: 0.0336 lr: 0.02\n","iteration: 16350 loss: 0.0325 lr: 0.02\n","iteration: 16400 loss: 0.0343 lr: 0.02\n","iteration: 16450 loss: 0.0310 lr: 0.02\n","iteration: 16500 loss: 0.0303 lr: 0.02\n","iteration: 16550 loss: 0.0288 lr: 0.02\n","iteration: 16600 loss: 0.0307 lr: 0.02\n","iteration: 16650 loss: 0.0310 lr: 0.02\n","iteration: 16700 loss: 0.0279 lr: 0.02\n","iteration: 16750 loss: 0.0325 lr: 0.02\n","iteration: 16800 loss: 0.0293 lr: 0.02\n","iteration: 16850 loss: 0.0314 lr: 0.02\n","iteration: 16900 loss: 0.0306 lr: 0.02\n","iteration: 16950 loss: 0.0337 lr: 0.02\n","iteration: 17000 loss: 0.0310 lr: 0.02\n","iteration: 17050 loss: 0.0298 lr: 0.02\n","iteration: 17100 loss: 0.0306 lr: 0.02\n","iteration: 17150 loss: 0.0331 lr: 0.02\n","iteration: 17200 loss: 0.0337 lr: 0.02\n","iteration: 17250 loss: 0.0319 lr: 0.02\n","iteration: 17300 loss: 0.0337 lr: 0.02\n","iteration: 17350 loss: 0.0304 lr: 0.02\n","iteration: 17400 loss: 0.0308 lr: 0.02\n","iteration: 17450 loss: 0.0300 lr: 0.02\n","iteration: 17500 loss: 0.0341 lr: 0.02\n","iteration: 17550 loss: 0.0312 lr: 0.02\n","iteration: 17600 loss: 0.0322 lr: 0.02\n","iteration: 17650 loss: 0.0322 lr: 0.02\n","iteration: 17700 loss: 0.0273 lr: 0.02\n","iteration: 17750 loss: 0.0288 lr: 0.02\n","iteration: 17800 loss: 0.0340 lr: 0.02\n","iteration: 17850 loss: 0.0329 lr: 0.02\n","iteration: 17900 loss: 0.0293 lr: 0.02\n","iteration: 17950 loss: 0.0308 lr: 0.02\n","iteration: 18000 loss: 0.0349 lr: 0.02\n","iteration: 18050 loss: 0.0333 lr: 0.02\n","iteration: 18100 loss: 0.0282 lr: 0.02\n","iteration: 18150 loss: 0.0340 lr: 0.02\n","iteration: 18200 loss: 0.0337 lr: 0.02\n","iteration: 18250 loss: 0.0281 lr: 0.02\n","iteration: 18300 loss: 0.0372 lr: 0.02\n","iteration: 18350 loss: 0.0307 lr: 0.02\n","iteration: 18400 loss: 0.0311 lr: 0.02\n","iteration: 18450 loss: 0.0349 lr: 0.02\n","iteration: 18500 loss: 0.0330 lr: 0.02\n","iteration: 18550 loss: 0.0312 lr: 0.02\n","iteration: 18600 loss: 0.0310 lr: 0.02\n","iteration: 18650 loss: 0.0313 lr: 0.02\n","iteration: 18700 loss: 0.0334 lr: 0.02\n","iteration: 18750 loss: 0.0297 lr: 0.02\n","iteration: 18800 loss: 0.0349 lr: 0.02\n","iteration: 18850 loss: 0.0323 lr: 0.02\n","iteration: 18900 loss: 0.0318 lr: 0.02\n","iteration: 18950 loss: 0.0288 lr: 0.02\n","iteration: 19000 loss: 0.0306 lr: 0.02\n","iteration: 19050 loss: 0.0294 lr: 0.02\n","iteration: 19100 loss: 0.0314 lr: 0.02\n","iteration: 19150 loss: 0.0336 lr: 0.02\n","iteration: 19200 loss: 0.0323 lr: 0.02\n","iteration: 19250 loss: 0.0330 lr: 0.02\n","iteration: 19300 loss: 0.0347 lr: 0.02\n","iteration: 19350 loss: 0.0319 lr: 0.02\n","iteration: 19400 loss: 0.0300 lr: 0.02\n","iteration: 19450 loss: 0.0352 lr: 0.02\n","iteration: 19500 loss: 0.0313 lr: 0.02\n","iteration: 19550 loss: 0.0347 lr: 0.02\n","iteration: 19600 loss: 0.0303 lr: 0.02\n","iteration: 19650 loss: 0.0375 lr: 0.02\n","iteration: 19700 loss: 0.0314 lr: 0.02\n","iteration: 19750 loss: 0.0329 lr: 0.02\n","iteration: 19800 loss: 0.0309 lr: 0.02\n","iteration: 19850 loss: 0.0304 lr: 0.02\n","iteration: 19900 loss: 0.0325 lr: 0.02\n","iteration: 19950 loss: 0.0294 lr: 0.02\n","iteration: 20000 loss: 0.0334 lr: 0.02\n","iteration: 20050 loss: 0.0298 lr: 0.02\n","iteration: 20100 loss: 0.0310 lr: 0.02\n","iteration: 20150 loss: 0.0324 lr: 0.02\n","iteration: 20200 loss: 0.0312 lr: 0.02\n","iteration: 20250 loss: 0.0323 lr: 0.02\n","iteration: 20300 loss: 0.0305 lr: 0.02\n","iteration: 20350 loss: 0.0334 lr: 0.02\n","iteration: 20400 loss: 0.0317 lr: 0.02\n","iteration: 20450 loss: 0.0279 lr: 0.02\n","iteration: 20500 loss: 0.0324 lr: 0.02\n","iteration: 20550 loss: 0.0325 lr: 0.02\n","iteration: 20600 loss: 0.0358 lr: 0.02\n","iteration: 20650 loss: 0.0291 lr: 0.02\n","iteration: 20700 loss: 0.0317 lr: 0.02\n","iteration: 20750 loss: 0.0308 lr: 0.02\n","iteration: 20800 loss: 0.0268 lr: 0.02\n","iteration: 20850 loss: 0.0325 lr: 0.02\n","iteration: 20900 loss: 0.0302 lr: 0.02\n","iteration: 20950 loss: 0.0316 lr: 0.02\n","iteration: 21000 loss: 0.0310 lr: 0.02\n","iteration: 21050 loss: 0.0330 lr: 0.02\n","iteration: 21100 loss: 0.0346 lr: 0.02\n","iteration: 21150 loss: 0.0357 lr: 0.02\n","iteration: 21200 loss: 0.0317 lr: 0.02\n","iteration: 21250 loss: 0.0326 lr: 0.02\n","iteration: 21300 loss: 0.0301 lr: 0.02\n","iteration: 21350 loss: 0.0321 lr: 0.02\n","iteration: 21400 loss: 0.0293 lr: 0.02\n","iteration: 21450 loss: 0.0325 lr: 0.02\n","iteration: 21500 loss: 0.0338 lr: 0.02\n","iteration: 21550 loss: 0.0317 lr: 0.02\n","iteration: 21600 loss: 0.0335 lr: 0.02\n","iteration: 21650 loss: 0.0333 lr: 0.02\n","iteration: 21700 loss: 0.0296 lr: 0.02\n","iteration: 21750 loss: 0.0333 lr: 0.02\n","iteration: 21800 loss: 0.0312 lr: 0.02\n","iteration: 21850 loss: 0.0321 lr: 0.02\n","iteration: 21900 loss: 0.0329 lr: 0.02\n","iteration: 21950 loss: 0.0276 lr: 0.02\n","iteration: 22000 loss: 0.0323 lr: 0.02\n","iteration: 22050 loss: 0.0299 lr: 0.02\n","iteration: 22100 loss: 0.0337 lr: 0.02\n","iteration: 22150 loss: 0.0327 lr: 0.02\n","iteration: 22200 loss: 0.0314 lr: 0.02\n","iteration: 22250 loss: 0.0272 lr: 0.02\n","iteration: 22300 loss: 0.0330 lr: 0.02\n","iteration: 22350 loss: 0.0290 lr: 0.02\n","iteration: 22400 loss: 0.0335 lr: 0.02\n","iteration: 22450 loss: 0.0339 lr: 0.02\n","iteration: 22500 loss: 0.0298 lr: 0.02\n","iteration: 22550 loss: 0.0321 lr: 0.02\n","iteration: 22600 loss: 0.0300 lr: 0.02\n","iteration: 22650 loss: 0.0334 lr: 0.02\n","iteration: 22700 loss: 0.0325 lr: 0.02\n","iteration: 22750 loss: 0.0327 lr: 0.02\n","iteration: 22800 loss: 0.0321 lr: 0.02\n","iteration: 22850 loss: 0.0311 lr: 0.02\n","iteration: 22900 loss: 0.0341 lr: 0.02\n","iteration: 22950 loss: 0.0302 lr: 0.02\n","iteration: 23000 loss: 0.0335 lr: 0.02\n","iteration: 23050 loss: 0.0322 lr: 0.02\n","iteration: 23100 loss: 0.0303 lr: 0.02\n","iteration: 23150 loss: 0.0329 lr: 0.02\n","iteration: 23200 loss: 0.0326 lr: 0.02\n","iteration: 23250 loss: 0.0332 lr: 0.02\n","iteration: 23300 loss: 0.0358 lr: 0.02\n","iteration: 23350 loss: 0.0311 lr: 0.02\n","iteration: 23400 loss: 0.0319 lr: 0.02\n","iteration: 23450 loss: 0.0337 lr: 0.02\n","iteration: 23500 loss: 0.0296 lr: 0.02\n","iteration: 23550 loss: 0.0306 lr: 0.02\n","iteration: 23600 loss: 0.0342 lr: 0.02\n","iteration: 23650 loss: 0.0350 lr: 0.02\n","iteration: 23700 loss: 0.0337 lr: 0.02\n","iteration: 23750 loss: 0.0347 lr: 0.02\n","iteration: 23800 loss: 0.0294 lr: 0.02\n","iteration: 23850 loss: 0.0310 lr: 0.02\n","iteration: 23900 loss: 0.0321 lr: 0.02\n","iteration: 23950 loss: 0.0316 lr: 0.02\n","iteration: 24000 loss: 0.0324 lr: 0.02\n","iteration: 24050 loss: 0.0335 lr: 0.02\n","iteration: 24100 loss: 0.0330 lr: 0.02\n","iteration: 24150 loss: 0.0321 lr: 0.02\n","iteration: 24200 loss: 0.0330 lr: 0.02\n","iteration: 24250 loss: 0.0332 lr: 0.02\n","iteration: 24300 loss: 0.0285 lr: 0.02\n","iteration: 24350 loss: 0.0303 lr: 0.02\n","iteration: 24400 loss: 0.0311 lr: 0.02\n","iteration: 24450 loss: 0.0318 lr: 0.02\n","iteration: 24500 loss: 0.0347 lr: 0.02\n","iteration: 24550 loss: 0.0343 lr: 0.02\n","iteration: 24600 loss: 0.0353 lr: 0.02\n","iteration: 24650 loss: 0.0308 lr: 0.02\n","iteration: 24700 loss: 0.0302 lr: 0.02\n","iteration: 24750 loss: 0.0339 lr: 0.02\n","iteration: 24800 loss: 0.0326 lr: 0.02\n","iteration: 24850 loss: 0.0298 lr: 0.02\n","iteration: 24900 loss: 0.0317 lr: 0.02\n","iteration: 24950 loss: 0.0293 lr: 0.02\n","iteration: 25000 loss: 0.0295 lr: 0.02\n","iteration: 25050 loss: 0.0321 lr: 0.02\n","iteration: 25100 loss: 0.0333 lr: 0.02\n","iteration: 25150 loss: 0.0289 lr: 0.02\n","iteration: 25200 loss: 0.0283 lr: 0.02\n","iteration: 25250 loss: 0.0308 lr: 0.02\n","iteration: 25300 loss: 0.0273 lr: 0.02\n","iteration: 25350 loss: 0.0293 lr: 0.02\n","iteration: 25400 loss: 0.0301 lr: 0.02\n","iteration: 25450 loss: 0.0321 lr: 0.02\n","iteration: 25500 loss: 0.0333 lr: 0.02\n","iteration: 25550 loss: 0.0299 lr: 0.02\n","iteration: 25600 loss: 0.0290 lr: 0.02\n","iteration: 25650 loss: 0.0325 lr: 0.02\n","iteration: 25700 loss: 0.0321 lr: 0.02\n","iteration: 25750 loss: 0.0311 lr: 0.02\n","iteration: 25800 loss: 0.0315 lr: 0.02\n","iteration: 25850 loss: 0.0323 lr: 0.02\n","iteration: 25900 loss: 0.0303 lr: 0.02\n","iteration: 25950 loss: 0.0371 lr: 0.02\n","iteration: 26000 loss: 0.0296 lr: 0.02\n","iteration: 26050 loss: 0.0312 lr: 0.02\n","iteration: 26100 loss: 0.0294 lr: 0.02\n","iteration: 26150 loss: 0.0305 lr: 0.02\n","iteration: 26200 loss: 0.0336 lr: 0.02\n","iteration: 26250 loss: 0.0349 lr: 0.02\n","iteration: 26300 loss: 0.0330 lr: 0.02\n","iteration: 26350 loss: 0.0314 lr: 0.02\n","iteration: 26400 loss: 0.0303 lr: 0.02\n","iteration: 26450 loss: 0.0347 lr: 0.02\n","iteration: 26500 loss: 0.0313 lr: 0.02\n","iteration: 26550 loss: 0.0335 lr: 0.02\n","iteration: 26600 loss: 0.0315 lr: 0.02\n","iteration: 26650 loss: 0.0311 lr: 0.02\n","iteration: 26700 loss: 0.0328 lr: 0.02\n","iteration: 26750 loss: 0.0320 lr: 0.02\n","iteration: 26800 loss: 0.0338 lr: 0.02\n","iteration: 26850 loss: 0.0347 lr: 0.02\n","iteration: 26900 loss: 0.0318 lr: 0.02\n","iteration: 26950 loss: 0.0311 lr: 0.02\n","iteration: 27000 loss: 0.0323 lr: 0.02\n","iteration: 27050 loss: 0.0327 lr: 0.02\n","iteration: 27100 loss: 0.0319 lr: 0.02\n","iteration: 27150 loss: 0.0303 lr: 0.02\n","iteration: 27200 loss: 0.0328 lr: 0.02\n","iteration: 27250 loss: 0.0307 lr: 0.02\n","iteration: 27300 loss: 0.0330 lr: 0.02\n","iteration: 27350 loss: 0.0331 lr: 0.02\n","iteration: 27400 loss: 0.0280 lr: 0.02\n","iteration: 27450 loss: 0.0336 lr: 0.02\n","iteration: 27500 loss: 0.0336 lr: 0.02\n","iteration: 27550 loss: 0.0261 lr: 0.02\n","iteration: 27600 loss: 0.0323 lr: 0.02\n","iteration: 27650 loss: 0.0318 lr: 0.02\n","iteration: 27700 loss: 0.0322 lr: 0.02\n","iteration: 27750 loss: 0.0316 lr: 0.02\n","iteration: 27800 loss: 0.0325 lr: 0.02\n","iteration: 27850 loss: 0.0312 lr: 0.02\n","iteration: 27900 loss: 0.0277 lr: 0.02\n","iteration: 27950 loss: 0.0349 lr: 0.02\n","iteration: 28000 loss: 0.0316 lr: 0.02\n","iteration: 28050 loss: 0.0348 lr: 0.02\n","iteration: 28100 loss: 0.0314 lr: 0.02\n","iteration: 28150 loss: 0.0279 lr: 0.02\n","iteration: 28200 loss: 0.0307 lr: 0.02\n","iteration: 28250 loss: 0.0295 lr: 0.02\n","iteration: 28300 loss: 0.0296 lr: 0.02\n","iteration: 28350 loss: 0.0338 lr: 0.02\n","iteration: 28400 loss: 0.0265 lr: 0.02\n","iteration: 28450 loss: 0.0320 lr: 0.02\n","iteration: 28500 loss: 0.0296 lr: 0.02\n","iteration: 28550 loss: 0.0357 lr: 0.02\n","iteration: 28600 loss: 0.0314 lr: 0.02\n","iteration: 28650 loss: 0.0322 lr: 0.02\n","iteration: 28700 loss: 0.0302 lr: 0.02\n","iteration: 28750 loss: 0.0325 lr: 0.02\n","iteration: 28800 loss: 0.0312 lr: 0.02\n","iteration: 28850 loss: 0.0324 lr: 0.02\n","iteration: 28900 loss: 0.0329 lr: 0.02\n","iteration: 28950 loss: 0.0289 lr: 0.02\n","iteration: 29000 loss: 0.0296 lr: 0.02\n","iteration: 29050 loss: 0.0315 lr: 0.02\n","iteration: 29100 loss: 0.0348 lr: 0.02\n","iteration: 29150 loss: 0.0320 lr: 0.02\n","iteration: 29200 loss: 0.0305 lr: 0.02\n","iteration: 29250 loss: 0.0336 lr: 0.02\n","iteration: 29300 loss: 0.0324 lr: 0.02\n","iteration: 29350 loss: 0.0315 lr: 0.02\n","iteration: 29400 loss: 0.0334 lr: 0.02\n","iteration: 29450 loss: 0.0309 lr: 0.02\n","iteration: 29500 loss: 0.0310 lr: 0.02\n","iteration: 29550 loss: 0.0313 lr: 0.02\n","iteration: 29600 loss: 0.0289 lr: 0.02\n","iteration: 29650 loss: 0.0310 lr: 0.02\n","iteration: 29700 loss: 0.0336 lr: 0.02\n","iteration: 29750 loss: 0.0327 lr: 0.02\n","iteration: 29800 loss: 0.0300 lr: 0.02\n","iteration: 29850 loss: 0.0319 lr: 0.02\n","iteration: 29900 loss: 0.0318 lr: 0.02\n","iteration: 29950 loss: 0.0293 lr: 0.02\n","iteration: 30000 loss: 0.0293 lr: 0.02\n","iteration: 30050 loss: 0.0322 lr: 0.02\n","iteration: 30100 loss: 0.0342 lr: 0.02\n","iteration: 30150 loss: 0.0324 lr: 0.02\n","iteration: 30200 loss: 0.0315 lr: 0.02\n","iteration: 30250 loss: 0.0325 lr: 0.02\n","iteration: 30300 loss: 0.0326 lr: 0.02\n","iteration: 30350 loss: 0.0311 lr: 0.02\n","iteration: 30400 loss: 0.0330 lr: 0.02\n","iteration: 30450 loss: 0.0322 lr: 0.02\n","iteration: 30500 loss: 0.0324 lr: 0.02\n","iteration: 30550 loss: 0.0287 lr: 0.02\n","iteration: 30600 loss: 0.0310 lr: 0.02\n","iteration: 30650 loss: 0.0305 lr: 0.02\n","iteration: 30700 loss: 0.0333 lr: 0.02\n","iteration: 30750 loss: 0.0306 lr: 0.02\n","iteration: 30800 loss: 0.0337 lr: 0.02\n","iteration: 30850 loss: 0.0320 lr: 0.02\n","iteration: 30900 loss: 0.0291 lr: 0.02\n","iteration: 30950 loss: 0.0352 lr: 0.02\n","iteration: 31000 loss: 0.0287 lr: 0.02\n","iteration: 31050 loss: 0.0336 lr: 0.02\n","iteration: 31100 loss: 0.0298 lr: 0.02\n","iteration: 31150 loss: 0.0296 lr: 0.02\n","iteration: 31200 loss: 0.0304 lr: 0.02\n","iteration: 31250 loss: 0.0315 lr: 0.02\n","iteration: 31300 loss: 0.0342 lr: 0.02\n","iteration: 31350 loss: 0.0308 lr: 0.02\n","iteration: 31400 loss: 0.0308 lr: 0.02\n","iteration: 31450 loss: 0.0315 lr: 0.02\n","iteration: 31500 loss: 0.0318 lr: 0.02\n","iteration: 31550 loss: 0.0326 lr: 0.02\n","iteration: 31600 loss: 0.0321 lr: 0.02\n","iteration: 31650 loss: 0.0311 lr: 0.02\n","iteration: 31700 loss: 0.0307 lr: 0.02\n","iteration: 31750 loss: 0.0327 lr: 0.02\n","iteration: 31800 loss: 0.0315 lr: 0.02\n","iteration: 31850 loss: 0.0317 lr: 0.02\n","iteration: 31900 loss: 0.0276 lr: 0.02\n","iteration: 31950 loss: 0.0307 lr: 0.02\n","iteration: 32000 loss: 0.0327 lr: 0.02\n","iteration: 32050 loss: 0.0295 lr: 0.02\n","iteration: 32100 loss: 0.0349 lr: 0.02\n","iteration: 32150 loss: 0.0324 lr: 0.02\n","iteration: 32200 loss: 0.0239 lr: 0.02\n","iteration: 32250 loss: 0.0369 lr: 0.02\n","iteration: 32300 loss: 0.0289 lr: 0.02\n","iteration: 32350 loss: 0.0319 lr: 0.02\n","iteration: 32400 loss: 0.0308 lr: 0.02\n","iteration: 32450 loss: 0.0309 lr: 0.02\n","iteration: 32500 loss: 0.0324 lr: 0.02\n","iteration: 32550 loss: 0.0308 lr: 0.02\n","iteration: 32600 loss: 0.0294 lr: 0.02\n","iteration: 32650 loss: 0.0332 lr: 0.02\n","iteration: 32700 loss: 0.0272 lr: 0.02\n","iteration: 32750 loss: 0.0333 lr: 0.02\n","iteration: 32800 loss: 0.0312 lr: 0.02\n","iteration: 32850 loss: 0.0330 lr: 0.02\n","iteration: 32900 loss: 0.0301 lr: 0.02\n","iteration: 32950 loss: 0.0278 lr: 0.02\n","iteration: 33000 loss: 0.0328 lr: 0.02\n","iteration: 33050 loss: 0.0291 lr: 0.02\n","iteration: 33100 loss: 0.0321 lr: 0.02\n","iteration: 33150 loss: 0.0293 lr: 0.02\n","iteration: 33200 loss: 0.0305 lr: 0.02\n","iteration: 33250 loss: 0.0300 lr: 0.02\n","iteration: 33300 loss: 0.0338 lr: 0.02\n","iteration: 33350 loss: 0.0315 lr: 0.02\n","iteration: 33400 loss: 0.0336 lr: 0.02\n","iteration: 33450 loss: 0.0332 lr: 0.02\n","iteration: 33500 loss: 0.0300 lr: 0.02\n","iteration: 33550 loss: 0.0301 lr: 0.02\n","iteration: 33600 loss: 0.0318 lr: 0.02\n","iteration: 33650 loss: 0.0324 lr: 0.02\n","iteration: 33700 loss: 0.0305 lr: 0.02\n","iteration: 33750 loss: 0.0302 lr: 0.02\n","iteration: 33800 loss: 0.0318 lr: 0.02\n","iteration: 33850 loss: 0.0304 lr: 0.02\n","iteration: 33900 loss: 0.0362 lr: 0.02\n","iteration: 33950 loss: 0.0334 lr: 0.02\n","iteration: 34000 loss: 0.0347 lr: 0.02\n","iteration: 34050 loss: 0.0358 lr: 0.02\n","iteration: 34100 loss: 0.0313 lr: 0.02\n","iteration: 34150 loss: 0.0336 lr: 0.02\n","iteration: 34200 loss: 0.0320 lr: 0.02\n","iteration: 34250 loss: 0.0339 lr: 0.02\n","iteration: 34300 loss: 0.0357 lr: 0.02\n","iteration: 34350 loss: 0.0295 lr: 0.02\n","iteration: 34400 loss: 0.0285 lr: 0.02\n","iteration: 34450 loss: 0.0299 lr: 0.02\n","iteration: 34500 loss: 0.0327 lr: 0.02\n","iteration: 34550 loss: 0.0303 lr: 0.02\n","iteration: 34600 loss: 0.0324 lr: 0.02\n","iteration: 34650 loss: 0.0317 lr: 0.02\n","iteration: 34700 loss: 0.0313 lr: 0.02\n","iteration: 34750 loss: 0.0317 lr: 0.02\n","iteration: 34800 loss: 0.0318 lr: 0.02\n","iteration: 34850 loss: 0.0301 lr: 0.02\n","iteration: 34900 loss: 0.0332 lr: 0.02\n","iteration: 34950 loss: 0.0328 lr: 0.02\n","iteration: 35000 loss: 0.0294 lr: 0.02\n","iteration: 35050 loss: 0.0310 lr: 0.02\n","iteration: 35100 loss: 0.0323 lr: 0.02\n","iteration: 35150 loss: 0.0328 lr: 0.02\n","iteration: 35200 loss: 0.0272 lr: 0.02\n","iteration: 35250 loss: 0.0347 lr: 0.02\n","iteration: 35300 loss: 0.0307 lr: 0.02\n","iteration: 35350 loss: 0.0286 lr: 0.02\n","iteration: 35400 loss: 0.0302 lr: 0.02\n","iteration: 35450 loss: 0.0333 lr: 0.02\n","iteration: 35500 loss: 0.0307 lr: 0.02\n","iteration: 35550 loss: 0.0310 lr: 0.02\n","iteration: 35600 loss: 0.0295 lr: 0.02\n","iteration: 35650 loss: 0.0345 lr: 0.02\n","iteration: 35700 loss: 0.0316 lr: 0.02\n","iteration: 35750 loss: 0.0311 lr: 0.02\n","iteration: 35800 loss: 0.0307 lr: 0.02\n","iteration: 35850 loss: 0.0335 lr: 0.02\n","iteration: 35900 loss: 0.0305 lr: 0.02\n","iteration: 35950 loss: 0.0315 lr: 0.02\n","iteration: 36000 loss: 0.0314 lr: 0.02\n","iteration: 36050 loss: 0.0308 lr: 0.02\n","iteration: 36100 loss: 0.0343 lr: 0.02\n","iteration: 36150 loss: 0.0309 lr: 0.02\n","iteration: 36200 loss: 0.0315 lr: 0.02\n","iteration: 36250 loss: 0.0345 lr: 0.02\n","iteration: 36300 loss: 0.0327 lr: 0.02\n","iteration: 36350 loss: 0.0328 lr: 0.02\n","iteration: 36400 loss: 0.0299 lr: 0.02\n","iteration: 36450 loss: 0.0308 lr: 0.02\n","iteration: 36500 loss: 0.0319 lr: 0.02\n","iteration: 36550 loss: 0.0305 lr: 0.02\n","iteration: 36600 loss: 0.0287 lr: 0.02\n","iteration: 36650 loss: 0.0335 lr: 0.02\n","iteration: 36700 loss: 0.0311 lr: 0.02\n","iteration: 36750 loss: 0.0318 lr: 0.02\n","iteration: 36800 loss: 0.0290 lr: 0.02\n","iteration: 36850 loss: 0.0290 lr: 0.02\n","iteration: 36900 loss: 0.0301 lr: 0.02\n","iteration: 36950 loss: 0.0329 lr: 0.02\n","iteration: 37000 loss: 0.0353 lr: 0.02\n","iteration: 37050 loss: 0.0289 lr: 0.02\n","iteration: 37100 loss: 0.0336 lr: 0.02\n","iteration: 37150 loss: 0.0316 lr: 0.02\n","iteration: 37200 loss: 0.0325 lr: 0.02\n","iteration: 37250 loss: 0.0300 lr: 0.02\n","iteration: 37300 loss: 0.0303 lr: 0.02\n","iteration: 37350 loss: 0.0297 lr: 0.02\n","iteration: 37400 loss: 0.0304 lr: 0.02\n","iteration: 37450 loss: 0.0289 lr: 0.02\n","iteration: 37500 loss: 0.0333 lr: 0.02\n","iteration: 37550 loss: 0.0316 lr: 0.02\n","iteration: 37600 loss: 0.0298 lr: 0.02\n","iteration: 37650 loss: 0.0314 lr: 0.02\n","iteration: 37700 loss: 0.0274 lr: 0.02\n","iteration: 37750 loss: 0.0291 lr: 0.02\n","iteration: 37800 loss: 0.0307 lr: 0.02\n","iteration: 37850 loss: 0.0299 lr: 0.02\n","iteration: 37900 loss: 0.0333 lr: 0.02\n","iteration: 37950 loss: 0.0308 lr: 0.02\n","iteration: 38000 loss: 0.0351 lr: 0.02\n","iteration: 38050 loss: 0.0348 lr: 0.02\n","iteration: 38100 loss: 0.0313 lr: 0.02\n","iteration: 38150 loss: 0.0320 lr: 0.02\n","iteration: 38200 loss: 0.0312 lr: 0.02\n","iteration: 38250 loss: 0.0324 lr: 0.02\n","iteration: 38300 loss: 0.0326 lr: 0.02\n","iteration: 38350 loss: 0.0356 lr: 0.02\n","iteration: 38400 loss: 0.0320 lr: 0.02\n","iteration: 38450 loss: 0.0331 lr: 0.02\n","iteration: 38500 loss: 0.0317 lr: 0.02\n","iteration: 38550 loss: 0.0322 lr: 0.02\n","iteration: 38600 loss: 0.0333 lr: 0.02\n","iteration: 38650 loss: 0.0324 lr: 0.02\n","iteration: 38700 loss: 0.0279 lr: 0.02\n","iteration: 38750 loss: 0.0327 lr: 0.02\n","iteration: 38800 loss: 0.0335 lr: 0.02\n","iteration: 38850 loss: 0.0319 lr: 0.02\n","iteration: 38900 loss: 0.0328 lr: 0.02\n","iteration: 38950 loss: 0.0295 lr: 0.02\n","iteration: 39000 loss: 0.0343 lr: 0.02\n","iteration: 39050 loss: 0.0314 lr: 0.02\n","iteration: 39100 loss: 0.0315 lr: 0.02\n","iteration: 39150 loss: 0.0293 lr: 0.02\n","iteration: 39200 loss: 0.0293 lr: 0.02\n","iteration: 39250 loss: 0.0335 lr: 0.02\n","iteration: 39300 loss: 0.0310 lr: 0.02\n","iteration: 39350 loss: 0.0313 lr: 0.02\n","iteration: 39400 loss: 0.0334 lr: 0.02\n","iteration: 39450 loss: 0.0304 lr: 0.02\n","iteration: 39500 loss: 0.0293 lr: 0.02\n","iteration: 39550 loss: 0.0301 lr: 0.02\n","iteration: 39600 loss: 0.0313 lr: 0.02\n","iteration: 39650 loss: 0.0322 lr: 0.02\n","iteration: 39700 loss: 0.0335 lr: 0.02\n","iteration: 39750 loss: 0.0310 lr: 0.02\n","iteration: 39800 loss: 0.0338 lr: 0.02\n","iteration: 39850 loss: 0.0305 lr: 0.02\n","iteration: 39900 loss: 0.0313 lr: 0.02\n","iteration: 39950 loss: 0.0317 lr: 0.02\n","iteration: 40000 loss: 0.0308 lr: 0.02\n","iteration: 40050 loss: 0.0315 lr: 0.02\n","iteration: 40100 loss: 0.0327 lr: 0.02\n","iteration: 40150 loss: 0.0337 lr: 0.02\n","iteration: 40200 loss: 0.0351 lr: 0.02\n","iteration: 40250 loss: 0.0322 lr: 0.02\n","iteration: 40300 loss: 0.0316 lr: 0.02\n","iteration: 40350 loss: 0.0354 lr: 0.02\n","iteration: 40400 loss: 0.0335 lr: 0.02\n","iteration: 40450 loss: 0.0287 lr: 0.02\n","iteration: 40500 loss: 0.0286 lr: 0.02\n","iteration: 40550 loss: 0.0299 lr: 0.02\n","iteration: 40600 loss: 0.0312 lr: 0.02\n","iteration: 40650 loss: 0.0315 lr: 0.02\n","iteration: 40700 loss: 0.0288 lr: 0.02\n","iteration: 40750 loss: 0.0311 lr: 0.02\n","iteration: 40800 loss: 0.0337 lr: 0.02\n","iteration: 40850 loss: 0.0377 lr: 0.02\n","iteration: 40900 loss: 0.0259 lr: 0.02\n","iteration: 40950 loss: 0.0328 lr: 0.02\n","iteration: 41000 loss: 0.0293 lr: 0.02\n","iteration: 41050 loss: 0.0276 lr: 0.02\n","iteration: 41100 loss: 0.0283 lr: 0.02\n","iteration: 41150 loss: 0.0345 lr: 0.02\n","iteration: 41200 loss: 0.0334 lr: 0.02\n","iteration: 41250 loss: 0.0301 lr: 0.02\n","iteration: 41300 loss: 0.0312 lr: 0.02\n","iteration: 41350 loss: 0.0313 lr: 0.02\n","iteration: 41400 loss: 0.0285 lr: 0.02\n","iteration: 41450 loss: 0.0348 lr: 0.02\n","iteration: 41500 loss: 0.0319 lr: 0.02\n","iteration: 41550 loss: 0.0327 lr: 0.02\n","iteration: 41600 loss: 0.0291 lr: 0.02\n","iteration: 41650 loss: 0.0306 lr: 0.02\n","iteration: 41700 loss: 0.0314 lr: 0.02\n","iteration: 41750 loss: 0.0324 lr: 0.02\n","iteration: 41800 loss: 0.0303 lr: 0.02\n","iteration: 41850 loss: 0.0316 lr: 0.02\n","iteration: 41900 loss: 0.0348 lr: 0.02\n","iteration: 41950 loss: 0.0333 lr: 0.02\n","iteration: 42000 loss: 0.0292 lr: 0.02\n","iteration: 42050 loss: 0.0331 lr: 0.02\n","iteration: 42100 loss: 0.0347 lr: 0.02\n","iteration: 42150 loss: 0.0325 lr: 0.02\n","iteration: 42200 loss: 0.0314 lr: 0.02\n","iteration: 42250 loss: 0.0349 lr: 0.02\n","iteration: 42300 loss: 0.0324 lr: 0.02\n","iteration: 42350 loss: 0.0321 lr: 0.02\n","iteration: 42400 loss: 0.0350 lr: 0.02\n","iteration: 42450 loss: 0.0312 lr: 0.02\n","iteration: 42500 loss: 0.0324 lr: 0.02\n","iteration: 42550 loss: 0.0323 lr: 0.02\n","iteration: 42600 loss: 0.0293 lr: 0.02\n","iteration: 42650 loss: 0.0300 lr: 0.02\n","iteration: 42700 loss: 0.0291 lr: 0.02\n","iteration: 42750 loss: 0.0282 lr: 0.02\n","iteration: 42800 loss: 0.0312 lr: 0.02\n","iteration: 42850 loss: 0.0300 lr: 0.02\n","iteration: 42900 loss: 0.0309 lr: 0.02\n","iteration: 42950 loss: 0.0292 lr: 0.02\n","iteration: 43000 loss: 0.0288 lr: 0.02\n","iteration: 43050 loss: 0.0334 lr: 0.02\n","iteration: 43100 loss: 0.0350 lr: 0.02\n","iteration: 43150 loss: 0.0294 lr: 0.02\n","iteration: 43200 loss: 0.0326 lr: 0.02\n","iteration: 43250 loss: 0.0306 lr: 0.02\n","iteration: 43300 loss: 0.0296 lr: 0.02\n","iteration: 43350 loss: 0.0341 lr: 0.02\n","iteration: 43400 loss: 0.0355 lr: 0.02\n","iteration: 43450 loss: 0.0346 lr: 0.02\n","iteration: 43500 loss: 0.0333 lr: 0.02\n","iteration: 43550 loss: 0.0318 lr: 0.02\n","iteration: 43600 loss: 0.0299 lr: 0.02\n","iteration: 43650 loss: 0.0302 lr: 0.02\n","iteration: 43700 loss: 0.0317 lr: 0.02\n","iteration: 43750 loss: 0.0287 lr: 0.02\n","iteration: 43800 loss: 0.0331 lr: 0.02\n","iteration: 43850 loss: 0.0306 lr: 0.02\n","iteration: 43900 loss: 0.0337 lr: 0.02\n","iteration: 43950 loss: 0.0315 lr: 0.02\n","iteration: 44000 loss: 0.0321 lr: 0.02\n","iteration: 44050 loss: 0.0310 lr: 0.02\n","iteration: 44100 loss: 0.0305 lr: 0.02\n","iteration: 44150 loss: 0.0297 lr: 0.02\n","iteration: 44200 loss: 0.0358 lr: 0.02\n","iteration: 44250 loss: 0.0304 lr: 0.02\n","iteration: 44300 loss: 0.0286 lr: 0.02\n","iteration: 44350 loss: 0.0334 lr: 0.02\n","iteration: 44400 loss: 0.0323 lr: 0.02\n","iteration: 44450 loss: 0.0320 lr: 0.02\n","iteration: 44500 loss: 0.0294 lr: 0.02\n","iteration: 44550 loss: 0.0306 lr: 0.02\n","iteration: 44600 loss: 0.0364 lr: 0.02\n","iteration: 44650 loss: 0.0342 lr: 0.02\n","iteration: 44700 loss: 0.0318 lr: 0.02\n","iteration: 44750 loss: 0.0357 lr: 0.02\n","iteration: 44800 loss: 0.0302 lr: 0.02\n","iteration: 44850 loss: 0.0302 lr: 0.02\n","iteration: 44900 loss: 0.0306 lr: 0.02\n","iteration: 44950 loss: 0.0335 lr: 0.02\n","iteration: 45000 loss: 0.0320 lr: 0.02\n","iteration: 45050 loss: 0.0290 lr: 0.02\n","iteration: 45100 loss: 0.0301 lr: 0.02\n","iteration: 45150 loss: 0.0302 lr: 0.02\n","iteration: 45200 loss: 0.0344 lr: 0.02\n","iteration: 45250 loss: 0.0313 lr: 0.02\n","iteration: 45300 loss: 0.0353 lr: 0.02\n","iteration: 45350 loss: 0.0320 lr: 0.02\n","iteration: 45400 loss: 0.0306 lr: 0.02\n","iteration: 45450 loss: 0.0288 lr: 0.02\n","iteration: 45500 loss: 0.0320 lr: 0.02\n","iteration: 45550 loss: 0.0338 lr: 0.02\n","iteration: 45600 loss: 0.0319 lr: 0.02\n","iteration: 45650 loss: 0.0344 lr: 0.02\n","iteration: 45700 loss: 0.0353 lr: 0.02\n","iteration: 45750 loss: 0.0316 lr: 0.02\n","iteration: 45800 loss: 0.0336 lr: 0.02\n","iteration: 45850 loss: 0.0301 lr: 0.02\n","iteration: 45900 loss: 0.0331 lr: 0.02\n","iteration: 45950 loss: 0.0293 lr: 0.02\n","iteration: 46000 loss: 0.0335 lr: 0.02\n","iteration: 46050 loss: 0.0329 lr: 0.02\n","iteration: 46100 loss: 0.0309 lr: 0.02\n","iteration: 46150 loss: 0.0307 lr: 0.02\n","iteration: 46200 loss: 0.0314 lr: 0.02\n","iteration: 46250 loss: 0.0334 lr: 0.02\n","iteration: 46300 loss: 0.0319 lr: 0.02\n","iteration: 46350 loss: 0.0308 lr: 0.02\n","iteration: 46400 loss: 0.0286 lr: 0.02\n","iteration: 46450 loss: 0.0344 lr: 0.02\n","iteration: 46500 loss: 0.0315 lr: 0.02\n","iteration: 46550 loss: 0.0318 lr: 0.02\n","iteration: 46600 loss: 0.0315 lr: 0.02\n","iteration: 46650 loss: 0.0296 lr: 0.02\n","iteration: 46700 loss: 0.0348 lr: 0.02\n","iteration: 46750 loss: 0.0332 lr: 0.02\n","iteration: 46800 loss: 0.0305 lr: 0.02\n","iteration: 46850 loss: 0.0337 lr: 0.02\n","iteration: 46900 loss: 0.0299 lr: 0.02\n","iteration: 46950 loss: 0.0319 lr: 0.02\n","iteration: 47000 loss: 0.0292 lr: 0.02\n","iteration: 47050 loss: 0.0299 lr: 0.02\n","iteration: 47100 loss: 0.0278 lr: 0.02\n","iteration: 47150 loss: 0.0310 lr: 0.02\n","iteration: 47200 loss: 0.0339 lr: 0.02\n","iteration: 47250 loss: 0.0300 lr: 0.02\n","iteration: 47300 loss: 0.0353 lr: 0.02\n","iteration: 47350 loss: 0.0341 lr: 0.02\n","iteration: 47400 loss: 0.0278 lr: 0.02\n","iteration: 47450 loss: 0.0341 lr: 0.02\n","iteration: 47500 loss: 0.0296 lr: 0.02\n","iteration: 47550 loss: 0.0339 lr: 0.02\n","iteration: 47600 loss: 0.0314 lr: 0.02\n","iteration: 47650 loss: 0.0296 lr: 0.02\n","iteration: 47700 loss: 0.0270 lr: 0.02\n","iteration: 47750 loss: 0.0306 lr: 0.02\n","iteration: 47800 loss: 0.0290 lr: 0.02\n","iteration: 47850 loss: 0.0327 lr: 0.02\n","iteration: 47900 loss: 0.0297 lr: 0.02\n","iteration: 47950 loss: 0.0327 lr: 0.02\n","iteration: 48000 loss: 0.0329 lr: 0.02\n","iteration: 48050 loss: 0.0303 lr: 0.02\n","iteration: 48100 loss: 0.0316 lr: 0.02\n","iteration: 48150 loss: 0.0299 lr: 0.02\n","iteration: 48200 loss: 0.0300 lr: 0.02\n","iteration: 48250 loss: 0.0316 lr: 0.02\n","iteration: 48300 loss: 0.0337 lr: 0.02\n","iteration: 48350 loss: 0.0297 lr: 0.02\n","iteration: 48400 loss: 0.0297 lr: 0.02\n","iteration: 48450 loss: 0.0304 lr: 0.02\n","iteration: 48500 loss: 0.0330 lr: 0.02\n","iteration: 48550 loss: 0.0295 lr: 0.02\n","iteration: 48600 loss: 0.0285 lr: 0.02\n","iteration: 48650 loss: 0.0328 lr: 0.02\n","iteration: 48700 loss: 0.0327 lr: 0.02\n","iteration: 48750 loss: 0.0357 lr: 0.02\n","iteration: 48800 loss: 0.0355 lr: 0.02\n","iteration: 48850 loss: 0.0296 lr: 0.02\n","iteration: 48900 loss: 0.0317 lr: 0.02\n","iteration: 48950 loss: 0.0294 lr: 0.02\n","iteration: 49000 loss: 0.0342 lr: 0.02\n","iteration: 49050 loss: 0.0323 lr: 0.02\n","iteration: 49100 loss: 0.0335 lr: 0.02\n","iteration: 49150 loss: 0.0295 lr: 0.02\n","iteration: 49200 loss: 0.0294 lr: 0.02\n","iteration: 49250 loss: 0.0328 lr: 0.02\n","iteration: 49300 loss: 0.0313 lr: 0.02\n","iteration: 49350 loss: 0.0329 lr: 0.02\n","iteration: 49400 loss: 0.0304 lr: 0.02\n","iteration: 49450 loss: 0.0318 lr: 0.02\n","iteration: 49500 loss: 0.0354 lr: 0.02\n","iteration: 49550 loss: 0.0342 lr: 0.02\n","iteration: 49600 loss: 0.0364 lr: 0.02\n","iteration: 49650 loss: 0.0320 lr: 0.02\n","iteration: 49700 loss: 0.0285 lr: 0.02\n","iteration: 49750 loss: 0.0315 lr: 0.02\n","iteration: 49800 loss: 0.0286 lr: 0.02\n","iteration: 49850 loss: 0.0305 lr: 0.02\n","iteration: 49900 loss: 0.0347 lr: 0.02\n","iteration: 49950 loss: 0.0360 lr: 0.02\n","iteration: 50000 loss: 0.0297 lr: 0.02\n","iteration: 50050 loss: 0.0327 lr: 0.02\n","iteration: 50100 loss: 0.0294 lr: 0.02\n","iteration: 50150 loss: 0.0279 lr: 0.02\n","iteration: 50200 loss: 0.0319 lr: 0.02\n","iteration: 50250 loss: 0.0324 lr: 0.02\n","iteration: 50300 loss: 0.0326 lr: 0.02\n","iteration: 50350 loss: 0.0330 lr: 0.02\n","iteration: 50400 loss: 0.0320 lr: 0.02\n","iteration: 50450 loss: 0.0347 lr: 0.02\n","iteration: 50500 loss: 0.0320 lr: 0.02\n","iteration: 50550 loss: 0.0352 lr: 0.02\n","iteration: 50600 loss: 0.0345 lr: 0.02\n","iteration: 50650 loss: 0.0319 lr: 0.02\n","iteration: 50700 loss: 0.0309 lr: 0.02\n","iteration: 50750 loss: 0.0343 lr: 0.02\n","iteration: 50800 loss: 0.0313 lr: 0.02\n","iteration: 50850 loss: 0.0298 lr: 0.02\n","iteration: 50900 loss: 0.0331 lr: 0.02\n","iteration: 50950 loss: 0.0324 lr: 0.02\n","iteration: 51000 loss: 0.0276 lr: 0.02\n","iteration: 51050 loss: 0.0343 lr: 0.02\n","iteration: 51100 loss: 0.0312 lr: 0.02\n","iteration: 51150 loss: 0.0318 lr: 0.02\n","iteration: 51200 loss: 0.0308 lr: 0.02\n","iteration: 51250 loss: 0.0295 lr: 0.02\n","iteration: 51300 loss: 0.0318 lr: 0.02\n","iteration: 51350 loss: 0.0284 lr: 0.02\n","iteration: 51400 loss: 0.0311 lr: 0.02\n","iteration: 51450 loss: 0.0315 lr: 0.02\n","iteration: 51500 loss: 0.0291 lr: 0.02\n","iteration: 51550 loss: 0.0313 lr: 0.02\n","iteration: 51600 loss: 0.0320 lr: 0.02\n","iteration: 51650 loss: 0.0324 lr: 0.02\n","iteration: 51700 loss: 0.0338 lr: 0.02\n","iteration: 51750 loss: 0.0300 lr: 0.02\n","iteration: 51800 loss: 0.0322 lr: 0.02\n","iteration: 51850 loss: 0.0280 lr: 0.02\n","iteration: 51900 loss: 0.0317 lr: 0.02\n","iteration: 51950 loss: 0.0307 lr: 0.02\n","iteration: 52000 loss: 0.0284 lr: 0.02\n","iteration: 52050 loss: 0.0310 lr: 0.02\n","iteration: 52100 loss: 0.0315 lr: 0.02\n","iteration: 52150 loss: 0.0310 lr: 0.02\n","iteration: 52200 loss: 0.0304 lr: 0.02\n","iteration: 52250 loss: 0.0323 lr: 0.02\n","iteration: 52300 loss: 0.0352 lr: 0.02\n","iteration: 52350 loss: 0.0301 lr: 0.02\n","iteration: 52400 loss: 0.0314 lr: 0.02\n","iteration: 52450 loss: 0.0302 lr: 0.02\n","iteration: 52500 loss: 0.0293 lr: 0.02\n","iteration: 52550 loss: 0.0322 lr: 0.02\n","iteration: 52600 loss: 0.0297 lr: 0.02\n","iteration: 52650 loss: 0.0310 lr: 0.02\n","iteration: 52700 loss: 0.0333 lr: 0.02\n","iteration: 52750 loss: 0.0282 lr: 0.02\n","iteration: 52800 loss: 0.0310 lr: 0.02\n","iteration: 52850 loss: 0.0347 lr: 0.02\n","iteration: 52900 loss: 0.0290 lr: 0.02\n","iteration: 52950 loss: 0.0312 lr: 0.02\n","iteration: 53000 loss: 0.0303 lr: 0.02\n","iteration: 53050 loss: 0.0292 lr: 0.02\n","iteration: 53100 loss: 0.0338 lr: 0.02\n","iteration: 53150 loss: 0.0260 lr: 0.02\n","iteration: 53200 loss: 0.0337 lr: 0.02\n","iteration: 53250 loss: 0.0281 lr: 0.02\n","iteration: 53300 loss: 0.0309 lr: 0.02\n","iteration: 53350 loss: 0.0315 lr: 0.02\n","iteration: 53400 loss: 0.0350 lr: 0.02\n","iteration: 53450 loss: 0.0349 lr: 0.02\n","iteration: 53500 loss: 0.0342 lr: 0.02\n","iteration: 53550 loss: 0.0311 lr: 0.02\n","iteration: 53600 loss: 0.0321 lr: 0.02\n","iteration: 53650 loss: 0.0341 lr: 0.02\n","iteration: 53700 loss: 0.0289 lr: 0.02\n","iteration: 53750 loss: 0.0333 lr: 0.02\n","iteration: 53800 loss: 0.0305 lr: 0.02\n","iteration: 53850 loss: 0.0339 lr: 0.02\n","iteration: 53900 loss: 0.0316 lr: 0.02\n","iteration: 53950 loss: 0.0325 lr: 0.02\n","iteration: 54000 loss: 0.0316 lr: 0.02\n","iteration: 54050 loss: 0.0340 lr: 0.02\n","iteration: 54100 loss: 0.0321 lr: 0.02\n","iteration: 54150 loss: 0.0347 lr: 0.02\n","iteration: 54200 loss: 0.0312 lr: 0.02\n","iteration: 54250 loss: 0.0320 lr: 0.02\n","iteration: 54300 loss: 0.0352 lr: 0.02\n","iteration: 54350 loss: 0.0310 lr: 0.02\n","iteration: 54400 loss: 0.0321 lr: 0.02\n","iteration: 54450 loss: 0.0303 lr: 0.02\n","iteration: 54500 loss: 0.0320 lr: 0.02\n","iteration: 54550 loss: 0.0319 lr: 0.02\n","iteration: 54600 loss: 0.0327 lr: 0.02\n","iteration: 54650 loss: 0.0295 lr: 0.02\n","iteration: 54700 loss: 0.0316 lr: 0.02\n","iteration: 54750 loss: 0.0299 lr: 0.02\n","iteration: 54800 loss: 0.0337 lr: 0.02\n","iteration: 54850 loss: 0.0342 lr: 0.02\n","iteration: 54900 loss: 0.0305 lr: 0.02\n","iteration: 54950 loss: 0.0312 lr: 0.02\n","iteration: 55000 loss: 0.0293 lr: 0.02\n","iteration: 55050 loss: 0.0299 lr: 0.02\n","iteration: 55100 loss: 0.0339 lr: 0.02\n","iteration: 55150 loss: 0.0319 lr: 0.02\n","iteration: 55200 loss: 0.0322 lr: 0.02\n","iteration: 55250 loss: 0.0290 lr: 0.02\n","iteration: 55300 loss: 0.0314 lr: 0.02\n","iteration: 55350 loss: 0.0303 lr: 0.02\n","iteration: 55400 loss: 0.0311 lr: 0.02\n","iteration: 55450 loss: 0.0329 lr: 0.02\n","iteration: 55500 loss: 0.0321 lr: 0.02\n","iteration: 55550 loss: 0.0328 lr: 0.02\n","iteration: 55600 loss: 0.0342 lr: 0.02\n","iteration: 55650 loss: 0.0320 lr: 0.02\n","iteration: 55700 loss: 0.0324 lr: 0.02\n","iteration: 55750 loss: 0.0331 lr: 0.02\n","iteration: 55800 loss: 0.0307 lr: 0.02\n","iteration: 55850 loss: 0.0314 lr: 0.02\n","iteration: 55900 loss: 0.0296 lr: 0.02\n","iteration: 55950 loss: 0.0314 lr: 0.02\n","iteration: 56000 loss: 0.0315 lr: 0.02\n","iteration: 56050 loss: 0.0320 lr: 0.02\n","iteration: 56100 loss: 0.0301 lr: 0.02\n","iteration: 56150 loss: 0.0287 lr: 0.02\n","iteration: 56200 loss: 0.0301 lr: 0.02\n","iteration: 56250 loss: 0.0330 lr: 0.02\n","iteration: 56300 loss: 0.0324 lr: 0.02\n","iteration: 56350 loss: 0.0304 lr: 0.02\n","iteration: 56400 loss: 0.0316 lr: 0.02\n","iteration: 56450 loss: 0.0301 lr: 0.02\n","iteration: 56500 loss: 0.0298 lr: 0.02\n","iteration: 56550 loss: 0.0332 lr: 0.02\n","iteration: 56600 loss: 0.0324 lr: 0.02\n","iteration: 56650 loss: 0.0306 lr: 0.02\n","iteration: 56700 loss: 0.0308 lr: 0.02\n","iteration: 56750 loss: 0.0291 lr: 0.02\n","iteration: 56800 loss: 0.0353 lr: 0.02\n","iteration: 56850 loss: 0.0303 lr: 0.02\n","iteration: 56900 loss: 0.0314 lr: 0.02\n","iteration: 56950 loss: 0.0323 lr: 0.02\n","iteration: 57000 loss: 0.0300 lr: 0.02\n","iteration: 57050 loss: 0.0328 lr: 0.02\n","iteration: 57100 loss: 0.0304 lr: 0.02\n","iteration: 57150 loss: 0.0336 lr: 0.02\n","iteration: 57200 loss: 0.0289 lr: 0.02\n","iteration: 57250 loss: 0.0309 lr: 0.02\n","iteration: 57300 loss: 0.0320 lr: 0.02\n","iteration: 57350 loss: 0.0347 lr: 0.02\n","iteration: 57400 loss: 0.0329 lr: 0.02\n","iteration: 57450 loss: 0.0311 lr: 0.02\n","iteration: 57500 loss: 0.0331 lr: 0.02\n","iteration: 57550 loss: 0.0334 lr: 0.02\n","iteration: 57600 loss: 0.0363 lr: 0.02\n","iteration: 57650 loss: 0.0279 lr: 0.02\n","iteration: 57700 loss: 0.0294 lr: 0.02\n","iteration: 57750 loss: 0.0263 lr: 0.02\n","iteration: 57800 loss: 0.0313 lr: 0.02\n","iteration: 57850 loss: 0.0318 lr: 0.02\n","iteration: 57900 loss: 0.0321 lr: 0.02\n","iteration: 57950 loss: 0.0291 lr: 0.02\n","iteration: 58000 loss: 0.0302 lr: 0.02\n","iteration: 58050 loss: 0.0299 lr: 0.02\n","iteration: 58100 loss: 0.0317 lr: 0.02\n","iteration: 58150 loss: 0.0307 lr: 0.02\n","iteration: 58200 loss: 0.0313 lr: 0.02\n","iteration: 58250 loss: 0.0268 lr: 0.02\n","iteration: 58300 loss: 0.0333 lr: 0.02\n","iteration: 58350 loss: 0.0298 lr: 0.02\n","iteration: 58400 loss: 0.0306 lr: 0.02\n","iteration: 58450 loss: 0.0324 lr: 0.02\n","iteration: 58500 loss: 0.0330 lr: 0.02\n","iteration: 58550 loss: 0.0329 lr: 0.02\n","iteration: 58600 loss: 0.0305 lr: 0.02\n","iteration: 58650 loss: 0.0303 lr: 0.02\n","iteration: 58700 loss: 0.0295 lr: 0.02\n","iteration: 58750 loss: 0.0301 lr: 0.02\n","iteration: 58800 loss: 0.0303 lr: 0.02\n","iteration: 58850 loss: 0.0322 lr: 0.02\n","iteration: 58900 loss: 0.0310 lr: 0.02\n","iteration: 58950 loss: 0.0338 lr: 0.02\n","iteration: 59000 loss: 0.0334 lr: 0.02\n","iteration: 59050 loss: 0.0312 lr: 0.02\n","iteration: 59100 loss: 0.0334 lr: 0.02\n","iteration: 59150 loss: 0.0298 lr: 0.02\n","iteration: 59200 loss: 0.0265 lr: 0.02\n","iteration: 59250 loss: 0.0349 lr: 0.02\n","iteration: 59300 loss: 0.0304 lr: 0.02\n","iteration: 59350 loss: 0.0283 lr: 0.02\n","iteration: 59400 loss: 0.0311 lr: 0.02\n","iteration: 59450 loss: 0.0300 lr: 0.02\n","iteration: 59500 loss: 0.0332 lr: 0.02\n","iteration: 59550 loss: 0.0296 lr: 0.02\n","iteration: 59600 loss: 0.0284 lr: 0.02\n","iteration: 59650 loss: 0.0338 lr: 0.02\n","iteration: 59700 loss: 0.0322 lr: 0.02\n","iteration: 59750 loss: 0.0353 lr: 0.02\n","iteration: 59800 loss: 0.0331 lr: 0.02\n","iteration: 59850 loss: 0.0308 lr: 0.02\n","iteration: 59900 loss: 0.0333 lr: 0.02\n","iteration: 59950 loss: 0.0342 lr: 0.02\n","iteration: 60000 loss: 0.0309 lr: 0.02\n","iteration: 60050 loss: 0.0364 lr: 0.02\n","iteration: 60100 loss: 0.0320 lr: 0.02\n","iteration: 60150 loss: 0.0334 lr: 0.02\n","iteration: 60200 loss: 0.0314 lr: 0.02\n","iteration: 60250 loss: 0.0321 lr: 0.02\n","iteration: 60300 loss: 0.0317 lr: 0.02\n","iteration: 60350 loss: 0.0313 lr: 0.02\n","iteration: 60400 loss: 0.0338 lr: 0.02\n","iteration: 60450 loss: 0.0342 lr: 0.02\n","iteration: 60500 loss: 0.0312 lr: 0.02\n","iteration: 60550 loss: 0.0317 lr: 0.02\n","iteration: 60600 loss: 0.0322 lr: 0.02\n","iteration: 60650 loss: 0.0281 lr: 0.02\n","iteration: 60700 loss: 0.0306 lr: 0.02\n","iteration: 60750 loss: 0.0322 lr: 0.02\n","iteration: 60800 loss: 0.0321 lr: 0.02\n","iteration: 60850 loss: 0.0326 lr: 0.02\n","iteration: 60900 loss: 0.0322 lr: 0.02\n","iteration: 60950 loss: 0.0305 lr: 0.02\n","iteration: 61000 loss: 0.0298 lr: 0.02\n","iteration: 61050 loss: 0.0286 lr: 0.02\n","iteration: 61100 loss: 0.0314 lr: 0.02\n","iteration: 61150 loss: 0.0345 lr: 0.02\n","iteration: 61200 loss: 0.0311 lr: 0.02\n","iteration: 61250 loss: 0.0310 lr: 0.02\n","iteration: 61300 loss: 0.0306 lr: 0.02\n","iteration: 61350 loss: 0.0284 lr: 0.02\n","iteration: 61400 loss: 0.0276 lr: 0.02\n","iteration: 61450 loss: 0.0307 lr: 0.02\n","iteration: 61500 loss: 0.0286 lr: 0.02\n","iteration: 61550 loss: 0.0348 lr: 0.02\n","iteration: 61600 loss: 0.0309 lr: 0.02\n","iteration: 61650 loss: 0.0306 lr: 0.02\n","iteration: 61700 loss: 0.0289 lr: 0.02\n","iteration: 61750 loss: 0.0318 lr: 0.02\n","iteration: 61800 loss: 0.0302 lr: 0.02\n","iteration: 61850 loss: 0.0307 lr: 0.02\n","iteration: 61900 loss: 0.0326 lr: 0.02\n","iteration: 61950 loss: 0.0303 lr: 0.02\n","iteration: 62000 loss: 0.0305 lr: 0.02\n","iteration: 62050 loss: 0.0299 lr: 0.02\n","iteration: 62100 loss: 0.0330 lr: 0.02\n","iteration: 62150 loss: 0.0317 lr: 0.02\n","iteration: 62200 loss: 0.0365 lr: 0.02\n","iteration: 62250 loss: 0.0291 lr: 0.02\n","iteration: 62300 loss: 0.0286 lr: 0.02\n","iteration: 62350 loss: 0.0343 lr: 0.02\n","iteration: 62400 loss: 0.0333 lr: 0.02\n","iteration: 62450 loss: 0.0319 lr: 0.02\n","iteration: 62500 loss: 0.0325 lr: 0.02\n","iteration: 62550 loss: 0.0322 lr: 0.02\n","iteration: 62600 loss: 0.0345 lr: 0.02\n","iteration: 62650 loss: 0.0309 lr: 0.02\n","iteration: 62700 loss: 0.0348 lr: 0.02\n","iteration: 62750 loss: 0.0286 lr: 0.02\n","iteration: 62800 loss: 0.0306 lr: 0.02\n","iteration: 62850 loss: 0.0300 lr: 0.02\n","iteration: 62900 loss: 0.0315 lr: 0.02\n","iteration: 62950 loss: 0.0318 lr: 0.02\n","iteration: 63000 loss: 0.0325 lr: 0.02\n","iteration: 63050 loss: 0.0324 lr: 0.02\n","iteration: 63100 loss: 0.0300 lr: 0.02\n","iteration: 63150 loss: 0.0319 lr: 0.02\n","iteration: 63200 loss: 0.0339 lr: 0.02\n","iteration: 63250 loss: 0.0337 lr: 0.02\n","iteration: 63300 loss: 0.0324 lr: 0.02\n","iteration: 63350 loss: 0.0306 lr: 0.02\n","iteration: 63400 loss: 0.0303 lr: 0.02\n","iteration: 63450 loss: 0.0306 lr: 0.02\n","iteration: 63500 loss: 0.0318 lr: 0.02\n","iteration: 63550 loss: 0.0291 lr: 0.02\n","iteration: 63600 loss: 0.0321 lr: 0.02\n","iteration: 63650 loss: 0.0351 lr: 0.02\n","iteration: 63700 loss: 0.0308 lr: 0.02\n","iteration: 63750 loss: 0.0327 lr: 0.02\n","iteration: 63800 loss: 0.0299 lr: 0.02\n","iteration: 63850 loss: 0.0325 lr: 0.02\n","iteration: 63900 loss: 0.0299 lr: 0.02\n","iteration: 63950 loss: 0.0299 lr: 0.02\n","iteration: 64000 loss: 0.0302 lr: 0.02\n","iteration: 64050 loss: 0.0309 lr: 0.02\n","iteration: 64100 loss: 0.0307 lr: 0.02\n","iteration: 64150 loss: 0.0300 lr: 0.02\n","iteration: 64200 loss: 0.0320 lr: 0.02\n","iteration: 64250 loss: 0.0314 lr: 0.02\n","iteration: 64300 loss: 0.0304 lr: 0.02\n","iteration: 64350 loss: 0.0324 lr: 0.02\n","iteration: 64400 loss: 0.0311 lr: 0.02\n","iteration: 64450 loss: 0.0320 lr: 0.02\n","iteration: 64500 loss: 0.0342 lr: 0.02\n","iteration: 64550 loss: 0.0330 lr: 0.02\n","iteration: 64600 loss: 0.0370 lr: 0.02\n","iteration: 64650 loss: 0.0286 lr: 0.02\n","iteration: 64700 loss: 0.0301 lr: 0.02\n","iteration: 64750 loss: 0.0316 lr: 0.02\n","iteration: 64800 loss: 0.0281 lr: 0.02\n","iteration: 64850 loss: 0.0375 lr: 0.02\n","iteration: 64900 loss: 0.0307 lr: 0.02\n","iteration: 64950 loss: 0.0277 lr: 0.02\n","iteration: 65000 loss: 0.0328 lr: 0.02\n","iteration: 65050 loss: 0.0335 lr: 0.02\n","iteration: 65100 loss: 0.0305 lr: 0.02\n","iteration: 65150 loss: 0.0320 lr: 0.02\n","iteration: 65200 loss: 0.0330 lr: 0.02\n","iteration: 65250 loss: 0.0312 lr: 0.02\n","iteration: 65300 loss: 0.0311 lr: 0.02\n","iteration: 65350 loss: 0.0337 lr: 0.02\n","iteration: 65400 loss: 0.0317 lr: 0.02\n","iteration: 65450 loss: 0.0322 lr: 0.02\n","iteration: 65500 loss: 0.0327 lr: 0.02\n","iteration: 65550 loss: 0.0320 lr: 0.02\n","iteration: 65600 loss: 0.0306 lr: 0.02\n","iteration: 65650 loss: 0.0339 lr: 0.02\n","iteration: 65700 loss: 0.0339 lr: 0.02\n","iteration: 65750 loss: 0.0295 lr: 0.02\n","iteration: 65800 loss: 0.0297 lr: 0.02\n","iteration: 65850 loss: 0.0345 lr: 0.02\n","iteration: 65900 loss: 0.0358 lr: 0.02\n","iteration: 65950 loss: 0.0301 lr: 0.02\n","iteration: 66000 loss: 0.0322 lr: 0.02\n","iteration: 66050 loss: 0.0343 lr: 0.02\n","iteration: 66100 loss: 0.0320 lr: 0.02\n","iteration: 66150 loss: 0.0310 lr: 0.02\n","iteration: 66200 loss: 0.0301 lr: 0.02\n","iteration: 66250 loss: 0.0305 lr: 0.02\n","iteration: 66300 loss: 0.0292 lr: 0.02\n","iteration: 66350 loss: 0.0302 lr: 0.02\n","iteration: 66400 loss: 0.0359 lr: 0.02\n","iteration: 66450 loss: 0.0315 lr: 0.02\n","iteration: 66500 loss: 0.0334 lr: 0.02\n","iteration: 66550 loss: 0.0347 lr: 0.02\n","iteration: 66600 loss: 0.0320 lr: 0.02\n","iteration: 66650 loss: 0.0280 lr: 0.02\n","iteration: 66700 loss: 0.0320 lr: 0.02\n","iteration: 66750 loss: 0.0323 lr: 0.02\n","iteration: 66800 loss: 0.0329 lr: 0.02\n","iteration: 66850 loss: 0.0319 lr: 0.02\n","iteration: 66900 loss: 0.0316 lr: 0.02\n","iteration: 66950 loss: 0.0349 lr: 0.02\n","iteration: 67000 loss: 0.0338 lr: 0.02\n","iteration: 67050 loss: 0.0319 lr: 0.02\n","iteration: 67100 loss: 0.0325 lr: 0.02\n","iteration: 67150 loss: 0.0314 lr: 0.02\n","iteration: 67200 loss: 0.0313 lr: 0.02\n","iteration: 67250 loss: 0.0330 lr: 0.02\n","iteration: 67300 loss: 0.0334 lr: 0.02\n","iteration: 67350 loss: 0.0272 lr: 0.02\n","iteration: 67400 loss: 0.0347 lr: 0.02\n","iteration: 67450 loss: 0.0310 lr: 0.02\n","iteration: 67500 loss: 0.0305 lr: 0.02\n","iteration: 67550 loss: 0.0312 lr: 0.02\n","iteration: 67600 loss: 0.0314 lr: 0.02\n","iteration: 67650 loss: 0.0311 lr: 0.02\n","iteration: 67700 loss: 0.0336 lr: 0.02\n","iteration: 67750 loss: 0.0320 lr: 0.02\n","iteration: 67800 loss: 0.0337 lr: 0.02\n","iteration: 67850 loss: 0.0315 lr: 0.02\n","iteration: 67900 loss: 0.0296 lr: 0.02\n","iteration: 67950 loss: 0.0376 lr: 0.02\n","iteration: 68000 loss: 0.0268 lr: 0.02\n","iteration: 68050 loss: 0.0285 lr: 0.02\n","iteration: 68100 loss: 0.0314 lr: 0.02\n","iteration: 68150 loss: 0.0272 lr: 0.02\n","iteration: 68200 loss: 0.0344 lr: 0.02\n","iteration: 68250 loss: 0.0282 lr: 0.02\n","iteration: 68300 loss: 0.0349 lr: 0.02\n","iteration: 68350 loss: 0.0315 lr: 0.02\n","iteration: 68400 loss: 0.0329 lr: 0.02\n","iteration: 68450 loss: 0.0299 lr: 0.02\n","iteration: 68500 loss: 0.0322 lr: 0.02\n","iteration: 68550 loss: 0.0311 lr: 0.02\n","iteration: 68600 loss: 0.0272 lr: 0.02\n","iteration: 68650 loss: 0.0307 lr: 0.02\n","iteration: 68700 loss: 0.0283 lr: 0.02\n","iteration: 68750 loss: 0.0308 lr: 0.02\n","iteration: 68800 loss: 0.0338 lr: 0.02\n","iteration: 68850 loss: 0.0307 lr: 0.02\n","iteration: 68900 loss: 0.0266 lr: 0.02\n","iteration: 68950 loss: 0.0298 lr: 0.02\n","iteration: 69000 loss: 0.0301 lr: 0.02\n","iteration: 69050 loss: 0.0304 lr: 0.02\n","iteration: 69100 loss: 0.0305 lr: 0.02\n","iteration: 69150 loss: 0.0280 lr: 0.02\n","iteration: 69200 loss: 0.0338 lr: 0.02\n","iteration: 69250 loss: 0.0308 lr: 0.02\n","iteration: 69300 loss: 0.0311 lr: 0.02\n","iteration: 69350 loss: 0.0314 lr: 0.02\n","iteration: 69400 loss: 0.0322 lr: 0.02\n","iteration: 69450 loss: 0.0329 lr: 0.02\n","iteration: 69500 loss: 0.0272 lr: 0.02\n","iteration: 69550 loss: 0.0291 lr: 0.02\n","iteration: 69600 loss: 0.0318 lr: 0.02\n","iteration: 69650 loss: 0.0318 lr: 0.02\n","iteration: 69700 loss: 0.0358 lr: 0.02\n","iteration: 69750 loss: 0.0320 lr: 0.02\n","iteration: 69800 loss: 0.0324 lr: 0.02\n","iteration: 69850 loss: 0.0319 lr: 0.02\n","iteration: 69900 loss: 0.0340 lr: 0.02\n","iteration: 69950 loss: 0.0319 lr: 0.02\n","iteration: 70000 loss: 0.0309 lr: 0.02\n","iteration: 70050 loss: 0.0301 lr: 0.02\n","iteration: 70100 loss: 0.0316 lr: 0.02\n","iteration: 70150 loss: 0.0334 lr: 0.02\n","iteration: 70200 loss: 0.0341 lr: 0.02\n","iteration: 70250 loss: 0.0319 lr: 0.02\n","iteration: 70300 loss: 0.0292 lr: 0.02\n","iteration: 70350 loss: 0.0346 lr: 0.02\n","iteration: 70400 loss: 0.0320 lr: 0.02\n","iteration: 70450 loss: 0.0277 lr: 0.02\n","iteration: 70500 loss: 0.0316 lr: 0.02\n","iteration: 70550 loss: 0.0330 lr: 0.02\n","iteration: 70600 loss: 0.0326 lr: 0.02\n","iteration: 70650 loss: 0.0332 lr: 0.02\n","iteration: 70700 loss: 0.0328 lr: 0.02\n","iteration: 70750 loss: 0.0317 lr: 0.02\n","iteration: 70800 loss: 0.0322 lr: 0.02\n","iteration: 70850 loss: 0.0325 lr: 0.02\n","iteration: 70900 loss: 0.0337 lr: 0.02\n","iteration: 70950 loss: 0.0321 lr: 0.02\n","iteration: 71000 loss: 0.0295 lr: 0.02\n","iteration: 71050 loss: 0.0324 lr: 0.02\n","iteration: 71100 loss: 0.0308 lr: 0.02\n","iteration: 71150 loss: 0.0333 lr: 0.02\n","iteration: 71200 loss: 0.0318 lr: 0.02\n","iteration: 71250 loss: 0.0311 lr: 0.02\n","iteration: 71300 loss: 0.0340 lr: 0.02\n","iteration: 71350 loss: 0.0369 lr: 0.02\n","iteration: 71400 loss: 0.0331 lr: 0.02\n","iteration: 71450 loss: 0.0327 lr: 0.02\n","iteration: 71500 loss: 0.0369 lr: 0.02\n","iteration: 71550 loss: 0.0292 lr: 0.02\n","iteration: 71600 loss: 0.0303 lr: 0.02\n","iteration: 71650 loss: 0.0355 lr: 0.02\n","iteration: 71700 loss: 0.0322 lr: 0.02\n","iteration: 71750 loss: 0.0342 lr: 0.02\n","iteration: 71800 loss: 0.0323 lr: 0.02\n","iteration: 71850 loss: 0.0286 lr: 0.02\n","iteration: 71900 loss: 0.0318 lr: 0.02\n","iteration: 71950 loss: 0.0308 lr: 0.02\n","iteration: 72000 loss: 0.0315 lr: 0.02\n","iteration: 72050 loss: 0.0325 lr: 0.02\n","iteration: 72100 loss: 0.0298 lr: 0.02\n","iteration: 72150 loss: 0.0310 lr: 0.02\n","iteration: 72200 loss: 0.0278 lr: 0.02\n","iteration: 72250 loss: 0.0337 lr: 0.02\n","iteration: 72300 loss: 0.0296 lr: 0.02\n","iteration: 72350 loss: 0.0305 lr: 0.02\n","iteration: 72400 loss: 0.0316 lr: 0.02\n","iteration: 72450 loss: 0.0321 lr: 0.02\n","iteration: 72500 loss: 0.0286 lr: 0.02\n","iteration: 72550 loss: 0.0305 lr: 0.02\n","iteration: 72600 loss: 0.0353 lr: 0.02\n","iteration: 72650 loss: 0.0288 lr: 0.02\n","iteration: 72700 loss: 0.0326 lr: 0.02\n","iteration: 72750 loss: 0.0342 lr: 0.02\n","iteration: 72800 loss: 0.0313 lr: 0.02\n","iteration: 72850 loss: 0.0304 lr: 0.02\n","iteration: 72900 loss: 0.0329 lr: 0.02\n","iteration: 72950 loss: 0.0324 lr: 0.02\n","iteration: 73000 loss: 0.0315 lr: 0.02\n","iteration: 73050 loss: 0.0311 lr: 0.02\n","iteration: 73100 loss: 0.0334 lr: 0.02\n","iteration: 73150 loss: 0.0319 lr: 0.02\n","iteration: 73200 loss: 0.0301 lr: 0.02\n","iteration: 73250 loss: 0.0282 lr: 0.02\n","iteration: 73300 loss: 0.0325 lr: 0.02\n","iteration: 73350 loss: 0.0353 lr: 0.02\n","iteration: 73400 loss: 0.0351 lr: 0.02\n","iteration: 73450 loss: 0.0353 lr: 0.02\n","iteration: 73500 loss: 0.0310 lr: 0.02\n","iteration: 73550 loss: 0.0322 lr: 0.02\n","iteration: 73600 loss: 0.0329 lr: 0.02\n","iteration: 73650 loss: 0.0332 lr: 0.02\n","iteration: 73700 loss: 0.0305 lr: 0.02\n","iteration: 73750 loss: 0.0317 lr: 0.02\n","iteration: 73800 loss: 0.0312 lr: 0.02\n","iteration: 73850 loss: 0.0310 lr: 0.02\n","iteration: 73900 loss: 0.0336 lr: 0.02\n","iteration: 73950 loss: 0.0339 lr: 0.02\n","iteration: 74000 loss: 0.0298 lr: 0.02\n","iteration: 74050 loss: 0.0368 lr: 0.02\n","iteration: 74100 loss: 0.0319 lr: 0.02\n","iteration: 74150 loss: 0.0331 lr: 0.02\n","iteration: 74200 loss: 0.0317 lr: 0.02\n","iteration: 74250 loss: 0.0288 lr: 0.02\n","iteration: 74300 loss: 0.0312 lr: 0.02\n","iteration: 74350 loss: 0.0312 lr: 0.02\n","iteration: 74400 loss: 0.0354 lr: 0.02\n","iteration: 74450 loss: 0.0356 lr: 0.02\n","iteration: 74500 loss: 0.0273 lr: 0.02\n","iteration: 74550 loss: 0.0293 lr: 0.02\n","iteration: 74600 loss: 0.0323 lr: 0.02\n","iteration: 74650 loss: 0.0302 lr: 0.02\n","iteration: 74700 loss: 0.0313 lr: 0.02\n","iteration: 74750 loss: 0.0340 lr: 0.02\n","iteration: 74800 loss: 0.0307 lr: 0.02\n","iteration: 74850 loss: 0.0332 lr: 0.02\n","iteration: 74900 loss: 0.0325 lr: 0.02\n","iteration: 74950 loss: 0.0327 lr: 0.02\n","iteration: 75000 loss: 0.0305 lr: 0.02\n","iteration: 75050 loss: 0.0302 lr: 0.02\n","iteration: 75100 loss: 0.0306 lr: 0.02\n","iteration: 75150 loss: 0.0345 lr: 0.02\n","iteration: 75200 loss: 0.0300 lr: 0.02\n","iteration: 75250 loss: 0.0305 lr: 0.02\n","iteration: 75300 loss: 0.0329 lr: 0.02\n","iteration: 75350 loss: 0.0328 lr: 0.02\n","iteration: 75400 loss: 0.0330 lr: 0.02\n","iteration: 75450 loss: 0.0299 lr: 0.02\n","iteration: 75500 loss: 0.0327 lr: 0.02\n","iteration: 75550 loss: 0.0293 lr: 0.02\n","iteration: 75600 loss: 0.0312 lr: 0.02\n","iteration: 75650 loss: 0.0307 lr: 0.02\n","iteration: 75700 loss: 0.0351 lr: 0.02\n","iteration: 75750 loss: 0.0303 lr: 0.02\n","iteration: 75800 loss: 0.0294 lr: 0.02\n","iteration: 75850 loss: 0.0330 lr: 0.02\n","iteration: 75900 loss: 0.0308 lr: 0.02\n","iteration: 75950 loss: 0.0333 lr: 0.02\n","iteration: 76000 loss: 0.0366 lr: 0.02\n","iteration: 76050 loss: 0.0274 lr: 0.02\n","iteration: 76100 loss: 0.0297 lr: 0.02\n","iteration: 76150 loss: 0.0313 lr: 0.02\n","iteration: 76200 loss: 0.0314 lr: 0.02\n","iteration: 76250 loss: 0.0337 lr: 0.02\n","iteration: 76300 loss: 0.0336 lr: 0.02\n","iteration: 76350 loss: 0.0333 lr: 0.02\n","iteration: 76400 loss: 0.0307 lr: 0.02\n","iteration: 76450 loss: 0.0316 lr: 0.02\n","iteration: 76500 loss: 0.0306 lr: 0.02\n","iteration: 76550 loss: 0.0342 lr: 0.02\n","iteration: 76600 loss: 0.0312 lr: 0.02\n","iteration: 76650 loss: 0.0353 lr: 0.02\n","iteration: 76700 loss: 0.0327 lr: 0.02\n","iteration: 76750 loss: 0.0301 lr: 0.02\n","iteration: 76800 loss: 0.0303 lr: 0.02\n","iteration: 76850 loss: 0.0290 lr: 0.02\n","iteration: 76900 loss: 0.0336 lr: 0.02\n","iteration: 76950 loss: 0.0347 lr: 0.02\n","iteration: 77000 loss: 0.0317 lr: 0.02\n","iteration: 77050 loss: 0.0295 lr: 0.02\n","iteration: 77100 loss: 0.0303 lr: 0.02\n","iteration: 77150 loss: 0.0318 lr: 0.02\n","iteration: 77200 loss: 0.0316 lr: 0.02\n","iteration: 77250 loss: 0.0311 lr: 0.02\n","iteration: 77300 loss: 0.0326 lr: 0.02\n","iteration: 77350 loss: 0.0287 lr: 0.02\n","iteration: 77400 loss: 0.0338 lr: 0.02\n","iteration: 77450 loss: 0.0308 lr: 0.02\n","iteration: 77500 loss: 0.0323 lr: 0.02\n","iteration: 77550 loss: 0.0340 lr: 0.02\n","iteration: 77600 loss: 0.0351 lr: 0.02\n","iteration: 77650 loss: 0.0339 lr: 0.02\n","iteration: 77700 loss: 0.0315 lr: 0.02\n","iteration: 77750 loss: 0.0304 lr: 0.02\n","iteration: 77800 loss: 0.0337 lr: 0.02\n","iteration: 77850 loss: 0.0329 lr: 0.02\n","iteration: 77900 loss: 0.0315 lr: 0.02\n","iteration: 77950 loss: 0.0348 lr: 0.02\n","iteration: 78000 loss: 0.0297 lr: 0.02\n","iteration: 78050 loss: 0.0279 lr: 0.02\n","iteration: 78100 loss: 0.0327 lr: 0.02\n","iteration: 78150 loss: 0.0348 lr: 0.02\n","iteration: 78200 loss: 0.0304 lr: 0.02\n","iteration: 78250 loss: 0.0307 lr: 0.02\n","iteration: 78300 loss: 0.0310 lr: 0.02\n","iteration: 78350 loss: 0.0278 lr: 0.02\n","iteration: 78400 loss: 0.0327 lr: 0.02\n","iteration: 78450 loss: 0.0294 lr: 0.02\n","iteration: 78500 loss: 0.0320 lr: 0.02\n","iteration: 78550 loss: 0.0311 lr: 0.02\n","iteration: 78600 loss: 0.0307 lr: 0.02\n","iteration: 78650 loss: 0.0327 lr: 0.02\n","iteration: 78700 loss: 0.0302 lr: 0.02\n","iteration: 78750 loss: 0.0352 lr: 0.02\n","iteration: 78800 loss: 0.0317 lr: 0.02\n","iteration: 78850 loss: 0.0302 lr: 0.02\n","iteration: 78900 loss: 0.0315 lr: 0.02\n","iteration: 78950 loss: 0.0312 lr: 0.02\n","iteration: 79000 loss: 0.0266 lr: 0.02\n","iteration: 79050 loss: 0.0301 lr: 0.02\n","iteration: 79100 loss: 0.0311 lr: 0.02\n","iteration: 79150 loss: 0.0301 lr: 0.02\n","iteration: 79200 loss: 0.0319 lr: 0.02\n","iteration: 79250 loss: 0.0305 lr: 0.02\n","iteration: 79300 loss: 0.0280 lr: 0.02\n","iteration: 79350 loss: 0.0323 lr: 0.02\n","iteration: 79400 loss: 0.0325 lr: 0.02\n","iteration: 79450 loss: 0.0298 lr: 0.02\n","iteration: 79500 loss: 0.0299 lr: 0.02\n","iteration: 79550 loss: 0.0292 lr: 0.02\n","iteration: 79600 loss: 0.0332 lr: 0.02\n","iteration: 79650 loss: 0.0337 lr: 0.02\n","iteration: 79700 loss: 0.0296 lr: 0.02\n","iteration: 79750 loss: 0.0312 lr: 0.02\n","iteration: 79800 loss: 0.0330 lr: 0.02\n","iteration: 79850 loss: 0.0320 lr: 0.02\n","iteration: 79900 loss: 0.0299 lr: 0.02\n","iteration: 79950 loss: 0.0309 lr: 0.02\n","iteration: 80000 loss: 0.0311 lr: 0.02\n","iteration: 80050 loss: 0.0332 lr: 0.02\n","iteration: 80100 loss: 0.0335 lr: 0.02\n","iteration: 80150 loss: 0.0282 lr: 0.02\n","iteration: 80200 loss: 0.0332 lr: 0.02\n","iteration: 80250 loss: 0.0342 lr: 0.02\n","iteration: 80300 loss: 0.0327 lr: 0.02\n","iteration: 80350 loss: 0.0328 lr: 0.02\n","iteration: 80400 loss: 0.0291 lr: 0.02\n","iteration: 80450 loss: 0.0349 lr: 0.02\n","iteration: 80500 loss: 0.0309 lr: 0.02\n","iteration: 80550 loss: 0.0332 lr: 0.02\n","iteration: 80600 loss: 0.0293 lr: 0.02\n","iteration: 80650 loss: 0.0289 lr: 0.02\n","iteration: 80700 loss: 0.0280 lr: 0.02\n","iteration: 80750 loss: 0.0336 lr: 0.02\n","iteration: 80800 loss: 0.0301 lr: 0.02\n","iteration: 80850 loss: 0.0352 lr: 0.02\n","iteration: 80900 loss: 0.0291 lr: 0.02\n","iteration: 80950 loss: 0.0321 lr: 0.02\n","iteration: 81000 loss: 0.0341 lr: 0.02\n","iteration: 81050 loss: 0.0325 lr: 0.02\n","iteration: 81100 loss: 0.0320 lr: 0.02\n","iteration: 81150 loss: 0.0304 lr: 0.02\n","iteration: 81200 loss: 0.0340 lr: 0.02\n","iteration: 81250 loss: 0.0307 lr: 0.02\n","iteration: 81300 loss: 0.0325 lr: 0.02\n","iteration: 81350 loss: 0.0340 lr: 0.02\n","iteration: 81400 loss: 0.0331 lr: 0.02\n","iteration: 81450 loss: 0.0341 lr: 0.02\n","iteration: 81500 loss: 0.0314 lr: 0.02\n","iteration: 81550 loss: 0.0315 lr: 0.02\n","iteration: 81600 loss: 0.0295 lr: 0.02\n","iteration: 81650 loss: 0.0306 lr: 0.02\n","iteration: 81700 loss: 0.0333 lr: 0.02\n","iteration: 81750 loss: 0.0305 lr: 0.02\n","iteration: 81800 loss: 0.0317 lr: 0.02\n","iteration: 81850 loss: 0.0330 lr: 0.02\n","iteration: 81900 loss: 0.0313 lr: 0.02\n","iteration: 81950 loss: 0.0310 lr: 0.02\n","iteration: 82000 loss: 0.0283 lr: 0.02\n","iteration: 82050 loss: 0.0328 lr: 0.02\n","iteration: 82100 loss: 0.0351 lr: 0.02\n","iteration: 82150 loss: 0.0314 lr: 0.02\n","iteration: 82200 loss: 0.0290 lr: 0.02\n","iteration: 82250 loss: 0.0312 lr: 0.02\n","iteration: 82300 loss: 0.0308 lr: 0.02\n","iteration: 82350 loss: 0.0311 lr: 0.02\n","iteration: 82400 loss: 0.0312 lr: 0.02\n","iteration: 82450 loss: 0.0341 lr: 0.02\n","iteration: 82500 loss: 0.0295 lr: 0.02\n","iteration: 82550 loss: 0.0320 lr: 0.02\n","iteration: 82600 loss: 0.0335 lr: 0.02\n","iteration: 82650 loss: 0.0291 lr: 0.02\n","iteration: 82700 loss: 0.0300 lr: 0.02\n","iteration: 82750 loss: 0.0327 lr: 0.02\n","iteration: 82800 loss: 0.0287 lr: 0.02\n","iteration: 82850 loss: 0.0292 lr: 0.02\n","iteration: 82900 loss: 0.0347 lr: 0.02\n","iteration: 82950 loss: 0.0283 lr: 0.02\n","iteration: 83000 loss: 0.0336 lr: 0.02\n","iteration: 83050 loss: 0.0328 lr: 0.02\n","iteration: 83100 loss: 0.0380 lr: 0.02\n","iteration: 83150 loss: 0.0290 lr: 0.02\n","iteration: 83200 loss: 0.0284 lr: 0.02\n","iteration: 83250 loss: 0.0342 lr: 0.02\n","iteration: 83300 loss: 0.0322 lr: 0.02\n","iteration: 83350 loss: 0.0323 lr: 0.02\n","iteration: 83400 loss: 0.0325 lr: 0.02\n","iteration: 83450 loss: 0.0309 lr: 0.02\n","iteration: 83500 loss: 0.0335 lr: 0.02\n","iteration: 83550 loss: 0.0301 lr: 0.02\n","iteration: 83600 loss: 0.0343 lr: 0.02\n","iteration: 83650 loss: 0.0341 lr: 0.02\n","iteration: 83700 loss: 0.0315 lr: 0.02\n","iteration: 83750 loss: 0.0330 lr: 0.02\n","iteration: 83800 loss: 0.0316 lr: 0.02\n","iteration: 83850 loss: 0.0330 lr: 0.02\n","iteration: 83900 loss: 0.0318 lr: 0.02\n","iteration: 83950 loss: 0.0301 lr: 0.02\n","iteration: 84000 loss: 0.0301 lr: 0.02\n","iteration: 84050 loss: 0.0321 lr: 0.02\n","iteration: 84100 loss: 0.0316 lr: 0.02\n","iteration: 84150 loss: 0.0294 lr: 0.02\n","iteration: 84200 loss: 0.0294 lr: 0.02\n","iteration: 84250 loss: 0.0342 lr: 0.02\n","iteration: 84300 loss: 0.0316 lr: 0.02\n","iteration: 84350 loss: 0.0285 lr: 0.02\n","iteration: 84400 loss: 0.0340 lr: 0.02\n","iteration: 84450 loss: 0.0333 lr: 0.02\n","iteration: 84500 loss: 0.0307 lr: 0.02\n","iteration: 84550 loss: 0.0317 lr: 0.02\n","iteration: 84600 loss: 0.0341 lr: 0.02\n","iteration: 84650 loss: 0.0298 lr: 0.02\n","iteration: 84700 loss: 0.0320 lr: 0.02\n","iteration: 84750 loss: 0.0320 lr: 0.02\n","iteration: 84800 loss: 0.0326 lr: 0.02\n","iteration: 84850 loss: 0.0320 lr: 0.02\n","iteration: 84900 loss: 0.0311 lr: 0.02\n","iteration: 84950 loss: 0.0344 lr: 0.02\n","iteration: 85000 loss: 0.0306 lr: 0.02\n","iteration: 85050 loss: 0.0356 lr: 0.02\n","iteration: 85100 loss: 0.0303 lr: 0.02\n","iteration: 85150 loss: 0.0306 lr: 0.02\n","iteration: 85200 loss: 0.0291 lr: 0.02\n","iteration: 85250 loss: 0.0306 lr: 0.02\n","iteration: 85300 loss: 0.0317 lr: 0.02\n","iteration: 85350 loss: 0.0336 lr: 0.02\n","iteration: 85400 loss: 0.0327 lr: 0.02\n","iteration: 85450 loss: 0.0306 lr: 0.02\n","iteration: 85500 loss: 0.0317 lr: 0.02\n","iteration: 85550 loss: 0.0332 lr: 0.02\n","iteration: 85600 loss: 0.0342 lr: 0.02\n","iteration: 85650 loss: 0.0297 lr: 0.02\n","iteration: 85700 loss: 0.0301 lr: 0.02\n","iteration: 85750 loss: 0.0285 lr: 0.02\n","iteration: 85800 loss: 0.0298 lr: 0.02\n","iteration: 85850 loss: 0.0324 lr: 0.02\n","iteration: 85900 loss: 0.0326 lr: 0.02\n","iteration: 85950 loss: 0.0303 lr: 0.02\n","iteration: 86000 loss: 0.0282 lr: 0.02\n","iteration: 86050 loss: 0.0302 lr: 0.02\n","iteration: 86100 loss: 0.0306 lr: 0.02\n","iteration: 86150 loss: 0.0330 lr: 0.02\n","iteration: 86200 loss: 0.0320 lr: 0.02\n","iteration: 86250 loss: 0.0319 lr: 0.02\n","iteration: 86300 loss: 0.0292 lr: 0.02\n","iteration: 86350 loss: 0.0270 lr: 0.02\n","iteration: 86400 loss: 0.0352 lr: 0.02\n","iteration: 86450 loss: 0.0364 lr: 0.02\n","iteration: 86500 loss: 0.0332 lr: 0.02\n","iteration: 86550 loss: 0.0315 lr: 0.02\n","iteration: 86600 loss: 0.0306 lr: 0.02\n","iteration: 86650 loss: 0.0299 lr: 0.02\n","iteration: 86700 loss: 0.0308 lr: 0.02\n","iteration: 86750 loss: 0.0291 lr: 0.02\n","iteration: 86800 loss: 0.0342 lr: 0.02\n","iteration: 86850 loss: 0.0321 lr: 0.02\n","iteration: 86900 loss: 0.0320 lr: 0.02\n","iteration: 86950 loss: 0.0311 lr: 0.02\n","iteration: 87000 loss: 0.0314 lr: 0.02\n","iteration: 87050 loss: 0.0292 lr: 0.02\n","iteration: 87100 loss: 0.0321 lr: 0.02\n","iteration: 87150 loss: 0.0297 lr: 0.02\n","iteration: 87200 loss: 0.0335 lr: 0.02\n","iteration: 87250 loss: 0.0311 lr: 0.02\n","iteration: 87300 loss: 0.0349 lr: 0.02\n","iteration: 87350 loss: 0.0325 lr: 0.02\n","iteration: 87400 loss: 0.0318 lr: 0.02\n","iteration: 87450 loss: 0.0347 lr: 0.02\n","iteration: 87500 loss: 0.0310 lr: 0.02\n","iteration: 87550 loss: 0.0357 lr: 0.02\n","iteration: 87600 loss: 0.0315 lr: 0.02\n","iteration: 87650 loss: 0.0302 lr: 0.02\n","iteration: 87700 loss: 0.0340 lr: 0.02\n","iteration: 87750 loss: 0.0278 lr: 0.02\n","iteration: 87800 loss: 0.0362 lr: 0.02\n","iteration: 87850 loss: 0.0343 lr: 0.02\n","iteration: 87900 loss: 0.0296 lr: 0.02\n","iteration: 87950 loss: 0.0311 lr: 0.02\n","iteration: 88000 loss: 0.0304 lr: 0.02\n","iteration: 88050 loss: 0.0316 lr: 0.02\n","iteration: 88100 loss: 0.0311 lr: 0.02\n","iteration: 88150 loss: 0.0317 lr: 0.02\n","iteration: 88200 loss: 0.0321 lr: 0.02\n","iteration: 88250 loss: 0.0302 lr: 0.02\n","iteration: 88300 loss: 0.0305 lr: 0.02\n","iteration: 88350 loss: 0.0317 lr: 0.02\n","iteration: 88400 loss: 0.0313 lr: 0.02\n","iteration: 88450 loss: 0.0336 lr: 0.02\n","iteration: 88500 loss: 0.0290 lr: 0.02\n","iteration: 88550 loss: 0.0318 lr: 0.02\n","iteration: 88600 loss: 0.0343 lr: 0.02\n","iteration: 88650 loss: 0.0339 lr: 0.02\n","iteration: 88700 loss: 0.0316 lr: 0.02\n","iteration: 88750 loss: 0.0349 lr: 0.02\n","iteration: 88800 loss: 0.0313 lr: 0.02\n","iteration: 88850 loss: 0.0316 lr: 0.02\n","iteration: 88900 loss: 0.0307 lr: 0.02\n","iteration: 88950 loss: 0.0309 lr: 0.02\n","iteration: 89000 loss: 0.0297 lr: 0.02\n","iteration: 89050 loss: 0.0281 lr: 0.02\n","iteration: 89100 loss: 0.0338 lr: 0.02\n","iteration: 89150 loss: 0.0353 lr: 0.02\n","iteration: 89200 loss: 0.0325 lr: 0.02\n","iteration: 89250 loss: 0.0351 lr: 0.02\n","iteration: 89300 loss: 0.0322 lr: 0.02\n","iteration: 89350 loss: 0.0343 lr: 0.02\n","iteration: 89400 loss: 0.0319 lr: 0.02\n","iteration: 89450 loss: 0.0340 lr: 0.02\n","iteration: 89500 loss: 0.0323 lr: 0.02\n","iteration: 89550 loss: 0.0368 lr: 0.02\n","iteration: 89600 loss: 0.0301 lr: 0.02\n","iteration: 89650 loss: 0.0273 lr: 0.02\n","iteration: 89700 loss: 0.0332 lr: 0.02\n","iteration: 89750 loss: 0.0318 lr: 0.02\n","iteration: 89800 loss: 0.0284 lr: 0.02\n","iteration: 89850 loss: 0.0308 lr: 0.02\n","iteration: 89900 loss: 0.0300 lr: 0.02\n","iteration: 89950 loss: 0.0294 lr: 0.02\n","iteration: 90000 loss: 0.0334 lr: 0.02\n","iteration: 90050 loss: 0.0310 lr: 0.02\n","iteration: 90100 loss: 0.0323 lr: 0.02\n","iteration: 90150 loss: 0.0297 lr: 0.02\n","iteration: 90200 loss: 0.0262 lr: 0.02\n","iteration: 90250 loss: 0.0342 lr: 0.02\n","iteration: 90300 loss: 0.0288 lr: 0.02\n","iteration: 90350 loss: 0.0329 lr: 0.02\n","iteration: 90400 loss: 0.0312 lr: 0.02\n","iteration: 90450 loss: 0.0317 lr: 0.02\n","iteration: 90500 loss: 0.0285 lr: 0.02\n","iteration: 90550 loss: 0.0309 lr: 0.02\n","iteration: 90600 loss: 0.0343 lr: 0.02\n","iteration: 90650 loss: 0.0323 lr: 0.02\n","iteration: 90700 loss: 0.0293 lr: 0.02\n","iteration: 90750 loss: 0.0312 lr: 0.02\n","iteration: 90800 loss: 0.0351 lr: 0.02\n","iteration: 90850 loss: 0.0324 lr: 0.02\n","iteration: 90900 loss: 0.0314 lr: 0.02\n","iteration: 90950 loss: 0.0303 lr: 0.02\n","iteration: 91000 loss: 0.0304 lr: 0.02\n","iteration: 91050 loss: 0.0302 lr: 0.02\n","iteration: 91100 loss: 0.0359 lr: 0.02\n","iteration: 91150 loss: 0.0299 lr: 0.02\n","iteration: 91200 loss: 0.0320 lr: 0.02\n","iteration: 91250 loss: 0.0308 lr: 0.02\n","iteration: 91300 loss: 0.0318 lr: 0.02\n","iteration: 91350 loss: 0.0273 lr: 0.02\n","iteration: 91400 loss: 0.0326 lr: 0.02\n","iteration: 91450 loss: 0.0314 lr: 0.02\n","iteration: 91500 loss: 0.0298 lr: 0.02\n","iteration: 91550 loss: 0.0329 lr: 0.02\n","iteration: 91600 loss: 0.0261 lr: 0.02\n","iteration: 91650 loss: 0.0331 lr: 0.02\n","iteration: 91700 loss: 0.0334 lr: 0.02\n","iteration: 91750 loss: 0.0247 lr: 0.02\n","iteration: 91800 loss: 0.0274 lr: 0.02\n","iteration: 91850 loss: 0.0325 lr: 0.02\n","iteration: 91900 loss: 0.0292 lr: 0.02\n","iteration: 91950 loss: 0.0320 lr: 0.02\n","iteration: 92000 loss: 0.0283 lr: 0.02\n","iteration: 92050 loss: 0.0345 lr: 0.02\n","iteration: 92100 loss: 0.0290 lr: 0.02\n","iteration: 92150 loss: 0.0325 lr: 0.02\n","iteration: 92200 loss: 0.0329 lr: 0.02\n","iteration: 92250 loss: 0.0305 lr: 0.02\n","iteration: 92300 loss: 0.0327 lr: 0.02\n","iteration: 92350 loss: 0.0332 lr: 0.02\n","iteration: 92400 loss: 0.0305 lr: 0.02\n","iteration: 92450 loss: 0.0278 lr: 0.02\n","iteration: 92500 loss: 0.0316 lr: 0.02\n","iteration: 92550 loss: 0.0315 lr: 0.02\n","iteration: 92600 loss: 0.0331 lr: 0.02\n","iteration: 92650 loss: 0.0332 lr: 0.02\n","iteration: 92700 loss: 0.0324 lr: 0.02\n","iteration: 92750 loss: 0.0315 lr: 0.02\n","iteration: 92800 loss: 0.0300 lr: 0.02\n","iteration: 92850 loss: 0.0278 lr: 0.02\n","iteration: 92900 loss: 0.0319 lr: 0.02\n","iteration: 92950 loss: 0.0341 lr: 0.02\n","iteration: 93000 loss: 0.0303 lr: 0.02\n","iteration: 93050 loss: 0.0276 lr: 0.02\n","iteration: 93100 loss: 0.0360 lr: 0.02\n","iteration: 93150 loss: 0.0297 lr: 0.02\n","iteration: 93200 loss: 0.0331 lr: 0.02\n","iteration: 93250 loss: 0.0317 lr: 0.02\n","iteration: 93300 loss: 0.0306 lr: 0.02\n","iteration: 93350 loss: 0.0344 lr: 0.02\n","iteration: 93400 loss: 0.0307 lr: 0.02\n","iteration: 93450 loss: 0.0328 lr: 0.02\n","iteration: 93500 loss: 0.0309 lr: 0.02\n","iteration: 93550 loss: 0.0322 lr: 0.02\n","iteration: 93600 loss: 0.0287 lr: 0.02\n","iteration: 93650 loss: 0.0341 lr: 0.02\n","iteration: 93700 loss: 0.0327 lr: 0.02\n","iteration: 93750 loss: 0.0312 lr: 0.02\n","iteration: 93800 loss: 0.0312 lr: 0.02\n","iteration: 93850 loss: 0.0317 lr: 0.02\n","iteration: 93900 loss: 0.0295 lr: 0.02\n","iteration: 93950 loss: 0.0256 lr: 0.02\n","iteration: 94000 loss: 0.0275 lr: 0.02\n","iteration: 94050 loss: 0.0320 lr: 0.02\n","iteration: 94100 loss: 0.0329 lr: 0.02\n","iteration: 94150 loss: 0.0282 lr: 0.02\n","iteration: 94200 loss: 0.0339 lr: 0.02\n","iteration: 94250 loss: 0.0290 lr: 0.02\n","iteration: 94300 loss: 0.0323 lr: 0.02\n","iteration: 94350 loss: 0.0332 lr: 0.02\n","iteration: 94400 loss: 0.0311 lr: 0.02\n","iteration: 94450 loss: 0.0286 lr: 0.02\n","iteration: 94500 loss: 0.0302 lr: 0.02\n","iteration: 94550 loss: 0.0289 lr: 0.02\n","iteration: 94600 loss: 0.0321 lr: 0.02\n","iteration: 94650 loss: 0.0333 lr: 0.02\n","iteration: 94700 loss: 0.0284 lr: 0.02\n","iteration: 94750 loss: 0.0292 lr: 0.02\n","iteration: 94800 loss: 0.0356 lr: 0.02\n","iteration: 94850 loss: 0.0346 lr: 0.02\n","iteration: 94900 loss: 0.0283 lr: 0.02\n","iteration: 94950 loss: 0.0318 lr: 0.02\n","iteration: 95000 loss: 0.0326 lr: 0.02\n","iteration: 95050 loss: 0.0289 lr: 0.02\n","iteration: 95100 loss: 0.0309 lr: 0.02\n","iteration: 95150 loss: 0.0348 lr: 0.02\n","iteration: 95200 loss: 0.0303 lr: 0.02\n","iteration: 95250 loss: 0.0349 lr: 0.02\n","iteration: 95300 loss: 0.0305 lr: 0.02\n","iteration: 95350 loss: 0.0292 lr: 0.02\n","iteration: 95400 loss: 0.0327 lr: 0.02\n","iteration: 95450 loss: 0.0322 lr: 0.02\n","iteration: 95500 loss: 0.0294 lr: 0.02\n","iteration: 95550 loss: 0.0299 lr: 0.02\n","iteration: 95600 loss: 0.0318 lr: 0.02\n","iteration: 95650 loss: 0.0330 lr: 0.02\n","iteration: 95700 loss: 0.0263 lr: 0.02\n","iteration: 95750 loss: 0.0311 lr: 0.02\n","iteration: 95800 loss: 0.0334 lr: 0.02\n","iteration: 95850 loss: 0.0367 lr: 0.02\n","iteration: 95900 loss: 0.0316 lr: 0.02\n","iteration: 95950 loss: 0.0335 lr: 0.02\n","iteration: 96000 loss: 0.0325 lr: 0.02\n","iteration: 96050 loss: 0.0317 lr: 0.02\n","iteration: 96100 loss: 0.0341 lr: 0.02\n","iteration: 96150 loss: 0.0355 lr: 0.02\n","iteration: 96200 loss: 0.0316 lr: 0.02\n","iteration: 96250 loss: 0.0315 lr: 0.02\n","iteration: 96300 loss: 0.0285 lr: 0.02\n","iteration: 96350 loss: 0.0303 lr: 0.02\n","iteration: 96400 loss: 0.0281 lr: 0.02\n","iteration: 96450 loss: 0.0295 lr: 0.02\n","iteration: 96500 loss: 0.0328 lr: 0.02\n","iteration: 96550 loss: 0.0308 lr: 0.02\n","iteration: 96600 loss: 0.0323 lr: 0.02\n","iteration: 96650 loss: 0.0327 lr: 0.02\n","iteration: 96700 loss: 0.0301 lr: 0.02\n","iteration: 96750 loss: 0.0318 lr: 0.02\n","iteration: 96800 loss: 0.0316 lr: 0.02\n","iteration: 96850 loss: 0.0315 lr: 0.02\n","iteration: 96900 loss: 0.0318 lr: 0.02\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-61c7b582415e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdlc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaveiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_growth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/drive/My Drive/Development/DeadROMM/deeplabcut/pose_estimation_tensorflow/training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/Development/DeadROMM/deeplabcut/pose_estimation_tensorflow/training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_VISIBLE_DEVICES'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgputouse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/Development/DeadROMM/deeplabcut/pose_estimation_tensorflow/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mcurrent_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         [_, loss_val, summary] = sess.run([train_op, total_loss, merged_summaries],\n\u001b[0;32m--> 190\u001b[0;31m                                           feed_dict={learning_rate: current_lr})\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0mcum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"NKnDEvVjYRWB","colab_type":"code","outputId":"ef3a8f33-846a-4e89-c1af-c3958e933762","executionInfo":{"status":"ok","timestamp":1590503270370,"user_tz":240,"elapsed":42210,"user":{"displayName":"Phil Fahn-Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgaLRzhwWuE2_ZNOkUUkb6lkk-noGiIsb7ucOzW=s64","userId":"13631433551768862211"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.dlc.evaluate_network(config_path)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /content/drive/My Drive/Development/DeadROMM/deeplabcut/pose_estimation_tensorflow/evaluate.py:242: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n","\n","/content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/evaluation-results/  already exists!\n"],"name":"stdout"},{"output_type":"stream","text":["Config:\n","{'all_joints': [[0],\n","                [1],\n","                [2],\n","                [3],\n","                [4],\n","                [5],\n","                [6],\n","                [7],\n","                [8],\n","                [9],\n","                [10],\n","                [11],\n","                [12],\n","                [13],\n","                [14],\n","                [15],\n","                [16],\n","                [17],\n","                [18],\n","                [19],\n","                [20],\n","                [21],\n","                [22],\n","                [23],\n","                [24],\n","                [25],\n","                [26],\n","                [27],\n","                [28],\n","                [29],\n","                [30],\n","                [31],\n","                [32],\n","                [33],\n","                [34],\n","                [35],\n","                [36],\n","                [37],\n","                [38],\n","                [39],\n","                [40],\n","                [41],\n","                [42],\n","                [43]],\n"," 'all_joints_names': ['Body_ds1_crn_cam1',\n","                      'Body_ds1_crn_cam2',\n","                      'Body_ds2_int_cam1',\n","                      'Body_ds2_int_cam2',\n","                      'Body_ds3_cdl_cam1',\n","                      'Body_ds3_cdl_cam2',\n","                      'Body_vn1_crn_cam1',\n","                      'Body_vn1_crn_cam2',\n","                      'Body_vn2_int_cam1',\n","                      'Body_vn2_int_cam2',\n","                      'Body_vn3_cdl_cam1',\n","                      'Body_vn3_cdl_cam2',\n","                      'Scapula_acr_cam1',\n","                      'Scapula_acr_cam2',\n","                      'Scapula_spi_cam1',\n","                      'Scapula_spi_cam2',\n","                      'Scapula_vtb_cam1',\n","                      'Scapula_vtb_cam2',\n","                      'Humerus_dpc_cam1',\n","                      'Humerus_dpc_cam2',\n","                      'Humerus_ent_cam1',\n","                      'Humerus_ent_cam2',\n","                      'Humerus_ect_cam1',\n","                      'Humerus_ect_cam2',\n","                      'Ulna_olc_cam1',\n","                      'Ulna_olc_cam2',\n","                      'Ulna_int_cam1',\n","                      'Ulna_int_cam2',\n","                      'Ulna_dst_cam1',\n","                      'Ulna_dst_cam2',\n","                      'Radius_prx_cam1',\n","                      'Radius_prx_cam2',\n","                      'Radius_int_cam1',\n","                      'Radius_int_cam2',\n","                      'Radius_dst_cam1',\n","                      'Radius_dst_cam2',\n","                      'Teres_maj_prx_cam1',\n","                      'Teres_maj_prx_cam2',\n","                      'Teres_maj_dst_cam1',\n","                      'Teres_maj_dst_cam2',\n","                      'Biceps_prx_cam1',\n","                      'Biceps_prx_cam2',\n","                      'Biceps_dst_cam1',\n","                      'Biceps_dst_cam2'],\n"," 'allchannelsclahe': True,\n"," 'augmentationprobability': 0.5,\n"," 'batch_size': 3,\n"," 'bottomheight': 400,\n"," 'covering': True,\n"," 'crop': True,\n"," 'crop_pad': 0,\n"," 'cropratio': 0.4,\n"," 'dataset': 'training-datasets/iteration-3/UnaugmentedDataSet_possum101_11AprApr13/possum101_11Apr_Phil95shuffle1.mat',\n"," 'dataset_type': 'imgaug',\n"," 'deconvolutionstride': 2,\n"," 'deterministic': False,\n"," 'display_iters': 1000,\n"," 'fg_fraction': 0.25,\n"," 'gamma': True,\n"," 'global_scale': 0.8,\n"," 'hist_eq': True,\n"," 'init_weights': '/content/drive/My '\n","                 'Drive/Development/DeadROMM/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n"," 'intermediate_supervision': False,\n"," 'intermediate_supervision_layer': 12,\n"," 'leftwidth': 400,\n"," 'location_refinement': True,\n"," 'locref_huber_loss': True,\n"," 'locref_loss_weight': 0.05,\n"," 'locref_stdev': 7.2801,\n"," 'log_dir': 'log',\n"," 'logcontrast': True,\n"," 'max_input_size': 1500,\n"," 'mean_pixel': [123.68, 116.779, 103.939],\n"," 'metadataset': 'training-datasets/iteration-3/UnaugmentedDataSet_possum101_11AprApr13/Documentation_data-possum101_11Apr_95shuffle1.pickle',\n"," 'min_input_size': 64,\n"," 'minsize': 100,\n"," 'mirror': False,\n"," 'multi_step': [[0.005, 10000],\n","                [0.02, 430000],\n","                [0.002, 730000],\n","                [0.001, 1030000]],\n"," 'net_type': 'resnet_50',\n"," 'num_joints': 44,\n"," 'optimizer': 'adam',\n"," 'output_stride': 16,\n"," 'pos_dist_thresh': 17,\n"," 'project_path': '/content/drive/My '\n","                 'Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff',\n"," 'regularize': False,\n"," 'rightwidth': 400,\n"," 'save_iters': 50000,\n"," 'scale_jitter_lo': 0.5,\n"," 'scale_jitter_up': 1.5,\n"," 'scoremap_dir': 'test',\n"," 'shuffle': True,\n"," 'snapshot_prefix': '/content/drive/My '\n","                    'Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/dlc-models/iteration-3/possum101_11AprApr13-trainset95shuffle1/test/snapshot',\n"," 'stride': 8.0,\n"," 'topheight': 400,\n"," 'weigh_negatives': False,\n"," 'weigh_only_present_joints': False,\n"," 'weigh_part_predictions': False,\n"," 'weight_decay': 0.0001}\n"],"name":"stderr"},{"output_type":"stream","text":["Running  DLC_resnet50_possum101_11AprApr13shuffle1_245000  with # of trainingiterations: 245000\n","Initializing ResNet\n","INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/dlc-models/iteration-3/possum101_11AprApr13-trainset95shuffle1/train/snapshot-245000\n"],"name":"stdout"},{"output_type":"stream","text":["\r0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Analyzing data...\n"],"name":"stdout"},{"output_type":"stream","text":["80it [00:12,  6.62it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Done and results stored for snapshot:  snapshot-245000\n","Results for 245000  training iterations: 95 1 train error: 1.33 pixels. Test error: 1.32  pixels.\n","With pcutoff of 0.1  train error: 1.33 pixels. Test error: 1.32 pixels\n","Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n","The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n","If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n","Use the function 'analyze_video' to make predictions on new videos.\n","Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_gSdFvUQYioM","colab_type":"code","outputId":"618955a7-36da-4efe-f333-d5ae001f1b19","executionInfo":{"status":"ok","timestamp":1590503752319,"user_tz":240,"elapsed":373116,"user":{"displayName":"Phil Fahn-Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgaLRzhwWuE2_ZNOkUUkb6lkk-noGiIsb7ucOzW=s64","userId":"13631433551768862211"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.dlc.analyze_videos(config_path,['/content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/videos/11Apr_diff.mp4'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Config:\n","{'all_joints': [[0],\n","                [1],\n","                [2],\n","                [3],\n","                [4],\n","                [5],\n","                [6],\n","                [7],\n","                [8],\n","                [9],\n","                [10],\n","                [11],\n","                [12],\n","                [13],\n","                [14],\n","                [15],\n","                [16],\n","                [17],\n","                [18],\n","                [19],\n","                [20],\n","                [21],\n","                [22],\n","                [23],\n","                [24],\n","                [25],\n","                [26],\n","                [27],\n","                [28],\n","                [29],\n","                [30],\n","                [31],\n","                [32],\n","                [33],\n","                [34],\n","                [35],\n","                [36],\n","                [37],\n","                [38],\n","                [39],\n","                [40],\n","                [41],\n","                [42],\n","                [43]],\n"," 'all_joints_names': ['Body_ds1_crn_cam1',\n","                      'Body_ds1_crn_cam2',\n","                      'Body_ds2_int_cam1',\n","                      'Body_ds2_int_cam2',\n","                      'Body_ds3_cdl_cam1',\n","                      'Body_ds3_cdl_cam2',\n","                      'Body_vn1_crn_cam1',\n","                      'Body_vn1_crn_cam2',\n","                      'Body_vn2_int_cam1',\n","                      'Body_vn2_int_cam2',\n","                      'Body_vn3_cdl_cam1',\n","                      'Body_vn3_cdl_cam2',\n","                      'Scapula_acr_cam1',\n","                      'Scapula_acr_cam2',\n","                      'Scapula_spi_cam1',\n","                      'Scapula_spi_cam2',\n","                      'Scapula_vtb_cam1',\n","                      'Scapula_vtb_cam2',\n","                      'Humerus_dpc_cam1',\n","                      'Humerus_dpc_cam2',\n","                      'Humerus_ent_cam1',\n","                      'Humerus_ent_cam2',\n","                      'Humerus_ect_cam1',\n","                      'Humerus_ect_cam2',\n","                      'Ulna_olc_cam1',\n","                      'Ulna_olc_cam2',\n","                      'Ulna_int_cam1',\n","                      'Ulna_int_cam2',\n","                      'Ulna_dst_cam1',\n","                      'Ulna_dst_cam2',\n","                      'Radius_prx_cam1',\n","                      'Radius_prx_cam2',\n","                      'Radius_int_cam1',\n","                      'Radius_int_cam2',\n","                      'Radius_dst_cam1',\n","                      'Radius_dst_cam2',\n","                      'Teres_maj_prx_cam1',\n","                      'Teres_maj_prx_cam2',\n","                      'Teres_maj_dst_cam1',\n","                      'Teres_maj_dst_cam2',\n","                      'Biceps_prx_cam1',\n","                      'Biceps_prx_cam2',\n","                      'Biceps_dst_cam1',\n","                      'Biceps_dst_cam2'],\n"," 'allchannelsclahe': True,\n"," 'augmentationprobability': 0.5,\n"," 'batch_size': 8,\n"," 'bottomheight': 400,\n"," 'covering': True,\n"," 'crop': True,\n"," 'crop_pad': 0,\n"," 'cropratio': 0.4,\n"," 'dataset': 'training-datasets/iteration-3/UnaugmentedDataSet_possum101_11AprApr13/possum101_11Apr_Phil95shuffle1.mat',\n"," 'dataset_type': 'imgaug',\n"," 'deconvolutionstride': 2,\n"," 'deterministic': False,\n"," 'display_iters': 1000,\n"," 'fg_fraction': 0.25,\n"," 'gamma': True,\n"," 'global_scale': 0.8,\n"," 'hist_eq': True,\n"," 'init_weights': '/content/drive/My '\n","                 'Drive/Development/DeadROMM/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n"," 'intermediate_supervision': False,\n"," 'intermediate_supervision_layer': 12,\n"," 'leftwidth': 400,\n"," 'location_refinement': True,\n"," 'locref_huber_loss': True,\n"," 'locref_loss_weight': 0.05,\n"," 'locref_stdev': 7.2801,\n"," 'log_dir': 'log',\n"," 'logcontrast': True,\n"," 'max_input_size': 1500,\n"," 'mean_pixel': [123.68, 116.779, 103.939],\n"," 'metadataset': 'training-datasets/iteration-3/UnaugmentedDataSet_possum101_11AprApr13/Documentation_data-possum101_11Apr_95shuffle1.pickle',\n"," 'min_input_size': 64,\n"," 'minsize': 100,\n"," 'mirror': False,\n"," 'multi_step': [[0.005, 10000],\n","                [0.02, 430000],\n","                [0.002, 730000],\n","                [0.001, 1030000]],\n"," 'net_type': 'resnet_50',\n"," 'num_joints': 44,\n"," 'num_outputs': 1,\n"," 'optimizer': 'adam',\n"," 'output_stride': 16,\n"," 'pos_dist_thresh': 17,\n"," 'project_path': '/content/drive/My '\n","                 'Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff',\n"," 'regularize': False,\n"," 'rightwidth': 400,\n"," 'save_iters': 50000,\n"," 'scale_jitter_lo': 0.5,\n"," 'scale_jitter_up': 1.5,\n"," 'scoremap_dir': 'test',\n"," 'shuffle': True,\n"," 'snapshot_prefix': '/content/drive/My '\n","                    'Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/dlc-models/iteration-3/possum101_11AprApr13-trainset95shuffle1/test/snapshot',\n"," 'stride': 8.0,\n"," 'topheight': 400,\n"," 'weigh_negatives': False,\n"," 'weigh_only_present_joints': False,\n"," 'weigh_part_predictions': False,\n"," 'weight_decay': 0.0001}\n"],"name":"stderr"},{"output_type":"stream","text":["Using snapshot-245000 for model /content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/dlc-models/iteration-3/possum101_11AprApr13-trainset95shuffle1\n","Initializing ResNet\n","INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/dlc-models/iteration-3/possum101_11AprApr13-trainset95shuffle1/train/snapshot-245000\n","Starting to analyze %  /content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/videos/11Apr_diff.mp4\n","Loading  /content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/videos/11Apr_diff.mp4\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/7904 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Duration of video [s]:  263.47 , recorded with  30.0 fps!\n","Overall # of frames:  7904  found with (before cropping) frame dimensions:  1024 1024\n","Starting to extract posture\n"],"name":"stdout"},{"output_type":"stream","text":["7979it [06:07, 21.69it/s]"],"name":"stderr"},{"output_type":"stream","text":["Detected frames:  7904\n","Saving results in /content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/videos...\n","The videos are analyzed. Now your research can truly start! \n"," You can create labeled videos with 'create_labeled_video'.\n","If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["'DLC_resnet50_possum101_11AprApr13shuffle1_245000'"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"Tn6ww5NZaXSh","colab_type":"code","outputId":"3a9e9402-a874-476f-f9d3-c7438e7e05a4","executionInfo":{"status":"ok","timestamp":1590503914935,"user_tz":240,"elapsed":134848,"user":{"displayName":"Phil Fahn-Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgaLRzhwWuE2_ZNOkUUkb6lkk-noGiIsb7ucOzW=s64","userId":"13631433551768862211"}},"colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["model.dlc.create_labeled_video(config_path,['/content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/videos/11Apr_diff.mp4'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Starting %  /content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/videos ['/content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/videos/11Apr_diff.mp4']\n","Loading  /content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/videos/11Apr_diff.mp4 and data.\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 13/7904 [00:00<01:05, 120.12it/s]"],"name":"stderr"},{"output_type":"stream","text":["7904\n","Duration of video [s]:  263.47 , recorded with  30.0 fps!\n","Overall # of frames:  7904 with cropped frame dimensions:  1024 1024\n","Generating frames and creating video.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|| 7904/7904 [02:13<00:00, 59.14it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"dZWt2jyJbozo","colab_type":"code","outputId":"1ba643be-2519-405c-9b47-fb63ec0d106f","executionInfo":{"status":"ok","timestamp":1590504272902,"user_tz":240,"elapsed":139908,"user":{"displayName":"Phil Fahn-Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgaLRzhwWuE2_ZNOkUUkb6lkk-noGiIsb7ucOzW=s64","userId":"13631433551768862211"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["\n","model.dlc.filterpredictions(config_path,['/content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/videos/11Apr_diff.mp4'], filtertype=\"spline\",windowlength=17)\n","model.dlc.create_labeled_video(config_path,['/content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/videos/11Apr_diff.mp4'],filtered=True)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["4it [00:00, 39.50it/s]"],"name":"stderr"},{"output_type":"stream","text":["Filtering with spline model /content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/videos/11Apr_diff.mp4\n"],"name":"stdout"},{"output_type":"stream","text":["44it [00:01, 38.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Saving filtered csv poses!\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/7904 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Starting %  /content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/videos ['/content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/videos/11Apr_diff.mp4']\n","Loading  /content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/videos/11Apr_diff.mp4 and data.\n","7904\n","Duration of video [s]:  263.47 , recorded with  30.0 fps!\n","Overall # of frames:  7904 with cropped frame dimensions:  1024 1024\n","Generating frames and creating video.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|| 7904/7904 [02:16<00:00, 57.86it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"R-1ytuoWudYB","colab_type":"code","outputId":"02d782c0-1783-48e3-f10a-5941d5f56cfb","executionInfo":{"status":"ok","timestamp":1590444349382,"user_tz":240,"elapsed":35624,"user":{"displayName":"Phil Fahn-Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgaLRzhwWuE2_ZNOkUUkb6lkk-noGiIsb7ucOzW=s64","userId":"13631433551768862211"}},"colab":{"base_uri":"https://localhost:8080/","height":258}},"source":["model.dlc.create_training_dataset(model.yaml,windows2linux=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/training-datasets/iteration-3/UnaugmentedDataSet_possum101_11AprApr13  already exists!\n","Annotation data converted to unix format...\n","/content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/dlc-models/iteration-3/possum101_11AprApr13-trainset95shuffle1  already exists!\n","/content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/dlc-models/iteration-3/possum101_11AprApr13-trainset95shuffle1/train  already exists!\n","/content/drive/My Drive/Development/DeadROMM/possum101_11Apr-Phil-2020-04-13-diff/dlc-models/iteration-3/possum101_11AprApr13-trainset95shuffle1/test  already exists!\n","The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[(0.95,\n","  1,\n","  (array([57, 62, 69, 32, 70,  1, 35, 29,  6, 66, 48, 79, 22, 44, 40, 36, 21,\n","           7, 10,  5, 43, 63,  8, 31, 55, 38, 33, 65, 41,  2, 73, 50, 24, 77,\n","          52, 53, 16, 64, 78, 67, 30, 72,  9, 71, 47, 75, 59, 23, 37, 19, 15,\n","          25, 76, 58, 20, 42, 14, 68, 74, 39, 49, 12, 56,  0, 46,  4, 27, 60,\n","          26, 34, 13, 54, 51, 45, 11, 28]), array([ 3, 17, 18, 61])))]"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"swrP1i3l2OFH","colab_type":"code","outputId":"25629f38-f360-4b99-bcd7-138d1c857544","executionInfo":{"status":"ok","timestamp":1590444878322,"user_tz":240,"elapsed":1208,"user":{"displayName":"Phil Fahn-Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgaLRzhwWuE2_ZNOkUUkb6lkk-noGiIsb7ucOzW=s64","userId":"13631433551768862211"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mon May 25 22:14:37 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P0    34W / 250W |  15767MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]}]}